---
title: "Implementing Buetti et al(2019)"
author: "ADF Clarke"
date: "24/08/2020"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")
```

# Setup and Data Import

```{r}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(magrittr)

# set ggplot2 theme
theme_set(see::theme_lucid())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# functions used for the analysis reimplementation
source("scripts/reimplementation.R")

# functions used for our Bayesian re-analysis
source("scripts/our_functions.R")

# used previously ran models, or refit. 
refit_models = FALSE
```

## Importing

We will import all experiments. While we're at it, we will remove error trials and very very short responses.

*What about very very long RTs? I'm not sure if there is a good reason to, or obvious cut off? Unlike for short Rts, in which values == 0 are mathematically impossible, and values <10ms are implausible. 
  
```{r import-data}
source("scripts/import_and_tidy.R")
 # remove error trials and very very short responses

print(dim(d))
d <- d %>%
  filter(error == 0) %T>% {print(dim(.))} %>%
  filter(rt > 0.025)  %T>% {print(dim(.))}
```

Do we want to register any other exclusion criteria? 
- min accuracy per participant?
- overly long RTs? 
- overly slow participants?
- incomplete data (i.e., did not complete the experiment)

[we would expect the data to be noisier due to online... so should build in some data quality checks]

# Computational Replication of Buetti et al (2019)

Before doing anything else (i.e., new), we want to confirm that we can replicate the original analysis.

## Calculating $D$

Calculate $D_e$ for each condition in each experiment. 

```{r}
De <- map_dfr(unique(d$exp_id), calc_D_per_feature, d)
```

## Predicing $D$

We can now predict values of $D$ for all experiments 2x and 4x. 

```{r}
Dp <- map_df(c("2a", "2b", "2c", "4a", "4b", "4c"), gen_exp_predictions, De)
```
 
Now, recreate the scatter plots from Buetti et al (2019), Figure 4.

```{r replicating-D-plot, fig.cap="Computational replication of Figure 4 (top row) from Buetti et al (2019)."}
left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(
    cols = c(`best feature`, `orthog. contrast`, collinear),
    values_to = "Dp",
    names_to = "method") %>%
  mutate(method = fct_relevel(method, "best feature", "orthog. contrast")) %>%
  ggplot(aes(x = Dp, y = D)) +
  geom_point() + 
  geom_abline(linetype = 2) +
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  coord_cartesian(xlim = c(0, 80), ylim = c(0, 80)) + 
  facet_wrap(~ method) + 
  scale_x_continuous("predicted D") + 
  scale_y_continuous("empirical D")
```

## Predicting Reaction Times

$L$ indicates the number of distractor types present in the display, $N_T$ is the total number of distractors, $N_i$ is the number of distractors of type $i$, $D_j$ indicates the logarithmic slope parameters associated with distractor of type $j$ (organized from smallest $D_1$ to largest $D_L$). Note that the $D$ parameter is the one that increases with increasing target-distractor similarity.

The constant a represents the reaction time when the target is alone in the display. Inter-item interactions were indexed by the multiplicative factor $\beta$. Finally, the index function $1_{[2, \infty)} (j)$ indicates that the sum over Ni only applies when there are at least two different types of lures in the display $(j > 1)$. When $j = 1$, the second sum is zero.

```{r pred-rt-replication, fig.width = 4, fig.cap="Computational Replication of RT predictions."}
exps2predict = c("2a", "2b", "2c", "4a", "4b", "4c")

rt_pred <- map_dfr(exps2predict, predict_rt)

d %>% filter(exp_id %in% exps2predict) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) %>% 
	ggplot(aes(x = p_rt, y = mean_rt)) + 
  geom_point(alpha = 0.5) + 
  geom_abline() + 
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  scale_x_continuous("predicted reaction time (ms)") +
  scale_y_continuous("empirical mean reaction time (ms)")
```
```{r tidy-up}
# remove variables we no longer need
rm(De, Dp)

```

<TODO> show RT predictions for the other two methods?

# Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use a lognormal distribution for modelling reaction times, This allows us to avoid ever predicing impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milli-seconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  
## Measuring $D$ from Empirical Data

We'll make a few minor changes to the data:
  - Switch from ms to seconds
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
  
```{r}
d %>% mutate(
  rt = rt/1000,
  exp_id = parse_number(exp_id)) -> d
```

### Prior Predictions

We can take the prior model, and then use it to compute our prior predictions!

```{r glmm-prior-sample, cache = TRUE}
mdl_inputs_nrl <- set_up_model(1, d, "normal")
prior_model_nrl <- run_model(mdl_inputs_nrl, ppc = "only")

mdl_inputs_log <- set_up_model("1", d, "lognormal")
prior_model_log <- run_model(mdl_inputs_log, ppc = "only")

mdl_inputs_sft <- set_up_model("1", d, "shifted_lognormal")
prior_model_sft <- run_model(mdl_inputs_sft, ppc = "only")
```

```{r plt-prior, fig.height=8, fig.cap="Sample Prior predictions for reaction time and log(N+1)."}
plt_nrl <- plot_model_fits_ex(d, 1, prior_model_nrl)
plt_log <- plot_model_fits_ex(d, 1, prior_model_log)
plt_sft <- plot_model_fits_ex(d, 1, prior_model_sft)
                             
plt_nrl / plt_log / plt_sft

# tidy up, we no longer need to keep hold of these models and plots
rm(
 prior_model_nrl, 
 prior_model_log, 
 prior_model_sft, 
 plt_nrl, plt_log, plt_sft)

```


### Fit Model and Posterior Predictions For Experiment 1

```{r glmm-compute-post-1}

if (refit_models)
{
  m_exp1_nrl <- run_model(mdl_inputs_nrl, ppc = "no")
  saveRDS(m_exp1_nrl, "models/exp_1_nrl.models")
  
  
  m_exp1_log <- run_model(mdl_inputs_log, ppc = "no")
  saveRDS(m_exp1_log, "models/exp_1_log.models")
  
  m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
  saveRDS(m_exp1_sft, "models/exp_1_sft.models")
  
} else {
  
  m_exp1_nrl <- readRDS("models/exp_1_nrl.models")
  m_exp1_log <- readRDS("models/exp_1_log.models")
  m_exp1_sft <- readRDS("models/exp_1_sft.models")
  
}

```

Calculate model weights to decide on best model...

```{r model-weights}
# loo_m_exp1_nrl <- loo(m_exp1_nrl)
# loo_m_exp1_log <- loo(m_exp1_log)
# 
# model_weights(m_exp1_nrl, m_exp1_log)
```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt-post, fig.height=5, fig.cap="Sample Prior predictions for reaction time and log(N+1).", cache=TRUE}

plt_nrl <- plot_model_fits_ex(d, 1, m_exp1_nrl)
plt_log <- plot_model_fits_ex(d, 1, m_exp1_log)
plt_sft <- plot_model_fits_ex(d, 1, m_exp1_sft)

plt_nrl / plt_log / plt_sft

rm(plt_nrl, plt_log, plt_sft)
```


### Fit Model and Posterior Predictions For Experiment 2, 3, and 4

Now that we have decided what the best distribution to use is, we will fit the model to the data from Experiment 2. 

```{r glmm-compute-post-234}

if (refit_models)
{
  mdl_inputs_nrl <- set_up_model("2", d, "normal")
  m_exp2_nrl <- run_model(mdl_inputs_nrl, ppc = "no")
  #save
  saveRDS(m_exp2_nrl, "models/exp_2_nrl.models")
  #tidy
  rm(mdl_inputs_nrl)
  
  mdl_inputs_log <- set_up_model("2", d, "lognormal")
  m_exp2_log <- run_model(mdl_inputs_log, ppc = "no")
  # save
  saveRDS(m_exp2_log, "models/exp_2_log.models")
   #tidy 
  rm(mdl_inputs_log)
   
  # mdl_inputs_sft <- set_up_model("2", d, "shifted_lognormal")
  # m_exp2_sft <- run_model(mdl_inputs_sft, ppc = "no")
  # # save
  # saveRDS(m_exp2_sft, "models/exp_2_sft.models")
  # #tidy
  # rm(mdl_inputs_sft)


} else {

  m_exp2_log <- readRDS("models/exp_2_log.models")
  # m_exp2_sft <- readRDS("models/exp_2_sft.models")
  # m_exp3_log <- readRDS("models/exp_3_log.models")
  # m_exp4_log <- readRDS("models/exp_4_log.models")
}
```

### Use these models to compute $D$

note, remove ` subset = 1:1000` when we've re-ran models with equal number of 
samples! (in the `extract_fixed_slopes_from_model()` function)

```{r compute-D-1, fig.cap="Posterior estimates for $D$."}
slopes1 <- extract_fixed_slopes_from_model(m_exp1_log)
ggplot(slopes1, aes(x= D, fill = d_feature)) + geom_density(alpha = 0.25)

ggsave("../plots/buetti2019_bayesian_fits.pdf", width = 8, height = 3)
```

## Estimating $D$ for compound feature distractors

```{r predict-D-2}
slopes2 <- extract_fixed_slopes_from_model(m_exp2_log)
Dp_samples <- get_Dp_samples(2, d, slopes1, slopes2)

rm(slopes1, slopes2)

Dp_samples %>% 
  group_by(exp_id, d_feature, method) %>%
  mean_hdci(Dp, De) %>%
  ggplot(aes(x = Dp, y = De)) +
  geom_abline(linetype = 2) +
  geom_point() +
  facet_wrap(~method, nrow = 1) + 
  geom_linerange(aes(ymin = De.lower, ymax = De.upper), alpha = 0.5) +
  geom_linerange(aes(xmin = Dp.lower, xmax = Dp.lower), alpha = 0.5) +
  geom_smooth(method = lm, colour = "pink")

ggsave("../plots/recreate_log_normal_fig_4.pdf", width = 8, height = 2.5)

```


## Predicting Reaction Times

```{r, fig.width = 10, fig.height = 10, cache=TRUE}
# in order to predict reaction times, we will specify a new version of our model
# It is a little bit hacky, but we can feed the predicted values for D into the 
# brms model as a prior, and then use that to simulate new trials.  

# first, summarise our Dp samples to give mu and sigma.
 Dp_samples %>%
   group_by(exp_id, d_feature, method) %>%
  summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop")-> Dp_summary

# now define and run new model! 
meth = "orthog_contrast"

model_params <- set_up_predict_model("2", d, "lognormal", meth, Dp_summary)
m_prt <-  run_model(model_params, ppc = "only")

```


```{r}
predict_rt_b(2, m_prt, d)
```


# Power Analyis for Planned Studies


What do the results look like if:

1) the same people do all parts of the study, and there is a correlation between tasks
2) We reduce the number of trials down to 96 per condition. 