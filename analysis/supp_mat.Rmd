---
title: "Implementing Buetti et al(2019)"
author: "ADF Clarke and AE Hughes"
date: "24/08/2020"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")
```

# Setup and Data Import

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)

```

```{r}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# functions used for the analysis reimplementation
source("scripts/reimplementation.R")

# functions used for our Bayesian re-analysis
source("scripts/our_functions.R")

```

## Importing

We will import all experiments. While we're at it, we will remove error trials and very very short responses.

*What about very very long RTs? I'm not sure if there is a good reason to, or obvious cut off? Unlike for short Rts, in which values == 0 are mathematically impossible, and values <10ms are implausible. 

We'll make a few minor changes to the data:
  - Switch from ms to seconds
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
  - Remove the bottom and top 1% of data
  
  
```{r import-data}
source("scripts/import_and_tidy.R")
```

Do we want to register any other exclusion criteria? 
- min accuracy per participant?
- overly long RTs? 
- overly slow participants?
- incomplete data (i.e., did not complete the experiment)

[we would expect the data to be noisier due to online... so should build in some data quality checks]

# Computational Replication of Buetti et al (2019)

Before doing anything else (i.e., new), we want to confirm that we can replicate the original analysis.

## Calculating $D$

Calculate $D_e$ for each condition in each experiment. 

```{r}
De <- map_dfr(unique(d$exp_id), calc_D_per_feature)
```

## Predicing $D$

We can now predict values of $D$ for all experiments 2x and 4x. 

```{r}
exps_to_predict <- c("2a", "2b", "2c", "4a", "4b", "4c")
Dp <- map_df(exps_to_predict, gen_exp_predictions, De)
```
 
Now, recreate the scatter plots from Buetti et al (2019), Figure 4.

```{r replicating-D-plot, fig.cap="Computational replication of Figure 4 (top row) from Buetti et al (2019)."}
left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(
    cols = c(`best feature`, `orthog. contrast`, collinear),
    values_to = "Dp",
    names_to = "method") %>%
  mutate(method = fct_relevel(method, "best feature", "orthog. contrast")) %>%
  ggplot(aes(x = Dp, y = D)) +
  geom_point( color = "yellow1") + 
  geom_abline(linetype = 2, colour = "cyan") +
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  # coord_cartesian(xlim = c(0, 80), ylim = c(0, 80)) + 
  facet_wrap(~ method) + 
  scale_x_continuous("predicted D") + 
  scale_y_continuous("empirical D")
```

```{r}
knitr::kable(De)
```

And compute $R^2$

```{r}
Dp_tmp <- left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(-c(exp_id, d_feature, D), names_to = "method", values_to = "Dp")

df_r2 <- tibble(exp_id = as.character(), method = as.character(), r2 = as.numeric())

for (e_id in exps_to_predict) {
  for (meth in unique(Dp_tmp$method)) {
    
    df <- filter(Dp_tmp, method == meth, exp_id == e_id)
    r2 <- summary(lm(D ~ Dp, data = df))$r.squared
    
    df_r2 <- add_row(df_r2, 
                      exp_id = paste("Exp", e_id), method = meth, r2 = r2)
  }  
}

 for (meth in unique(Dp_tmp$method)) {
  df <- filter(Dp_tmp, method == meth)
  r2 <- summary(lm(D ~ Dp, data = df))$r.squared
  print(meth)
  print(summary(lm(D ~ Dp, data = df))$r.squared)
  df_r2 <- add_row(df_r2, 
                 exp_id = "all", method = meth, r2 = r2)
 }

df_r2 %>% pivot_wider(method, names_from = "exp_id", values_from = "r2") %>%
  knitr::kable(digits =3)

rm(df_r2, Dp_tmp)

```

## Predicting Reaction Times

$L$ indicates the number of distractor types present in the display, $N_T$ is the total number of distractors, $N_i$ is the number of distractors of type $i$, $D_j$ indicates the logarithmic slope parameters associated with distractor of type $j$ (organized from smallest $D_1$ to largest $D_L$). Note that the $D$ parameter is the one that increases with increasing target-distractor similarity.

The constant a represents the reaction time when the target is alone in the display. Inter-item interactions were indexed by the multiplicative factor $\beta$. Finally, the index function $1_{[2, \infty)} (j)$ indicates that the sum over Ni only applies when there are at least two different types of lures in the display $(j > 1)$. When $j = 1$, the second sum is zero.

```{r pred-rt-replication, fig.width = 4, fig.cap="Computational Replication of RT predictions."}

rt_pred <- map_dfr(exps_to_predict, predict_rt)

d %>% filter(exp_id %in% exps_to_predict) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) %>% 
	ggplot(aes(x = p_rt, y = mean_rt)) + 
  geom_point(color = "yellow1", alpha = 0.5) + 
  geom_abline() + 
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  scale_x_continuous("predicted reaction time (ms)") +
  scale_y_continuous("empirical mean reaction time (ms)")

```

Compute correlation!
```{r}
d %>% filter(exp_id %in% exps_to_predict, N_T > 0) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) -> d_corr

round(summary(lm(mean_rt ~ p_rt, d_corr))$r.squared,2)

```
The $R^2= `r,round(summary(lm(mean_rt ~ p_rt, d_corr))$r.squared,2)`

```{r tidy-up}

# remove variables we no longer need
rm(De, Dp, rt_pred, exps_to_predict, 
   calc_D_per_feature, extract_a_value, predict_D_overall, gen_exp_predictions, extract_D, predict_rt, d_corr)
```

# Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use a lognormal distribution for modelling reaction times, This allows us to avoid ever predicing impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milli-seconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  
  
```{r}
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4 
# remove outlier RTs
d <- our_changes_to_data(d)
```

## Measuring $D$ from Empirical Data


### Prior Predictions

We can take the prior model, and then use it to compute our prior predictions!

```{r glmm-prior-sample}

  prior_model_nrl <- readRDS("models/prior_nrl.models")
  prior_model_log <- readRDS("models/prior_log.models")
  prior_model_sft <- readRDS("models/prior_sft.models")

```

```{r plt-prior, fig.height=3, fig.cap="Sample Prior predictions for reaction time and log(N+1)."}

plt_nrl <- plot_model_fits_rt(1, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "blue")
plt_log <- plot_model_fits_rt(1, prior_model_log, y_limits = c(0, 10), feature2plot = "blue")
plt_sft <- plot_model_fits_rt(1, prior_model_sft, y_limits = c(0, 10), feature2plot = "blue")
                             
plt_nrl + plt_log + plt_sft

# tidy up, we no longer need to keep hold of these models and plots
rm(
 prior_model_nrl, 
 prior_model_log, 
 prior_model_sft, 
 plt_nrl, plt_log, plt_sft)
```

### Fit Model and Posterior Predictions For Experiment 1

```{r glmm-compute-post-1}

m_exp1_nrl <- readRDS("models/exp_1_nrl.models")
m_exp1_log <- readRDS("models/exp_1_log.models")
m_exp1_sft <- readRDS("models/exp_1_sft.models")

```

Calculate model weights to decide on best model...


```{r model-weights, cache = TRUE}

loo_m_exp1_nrl <- readRDS("models/loo_m_exp1_nrl.rds")
loo_m_exp1_log <- readRDS("models/loo_m_exp1_log.rds")
loo_m_exp1_sft <- readRDS("models/loo_m_exp1_sft.rds")

loo_list <- list(loo_m_exp1_nrl, loo_m_exp1_log, loo_m_exp1_sft)
loo_model_weights(loo_list)

```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt-post, fig.height=7, fig.cap="Posterior predictions for reaction time and log(N+1)."}

plt_nrl <- plot_model_fits_rt(1, m_exp1_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(1, m_exp1_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(1, m_exp1_sft, plot_type = "fitted")

plt_nrl / plt_log / plt_sft

rm(plt_nrl, plt_log, plt_sft)
```

```{r plt-post-re, fig.height=7, fig.cap="Posterior predictions for reaction time and log(N+1)."}

plt_nrl <- plot_model_fits_rt(1, m_exp1_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(1, m_exp1_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(1, m_exp1_sft, plot_type = "predicted", y_limits = c(0, 2.5))

plt_nrl / plt_log / plt_sft

rm(plt_nrl, plt_log, plt_sft)
```

### Fit Model and Posterior Predictions For Experiment 2, 3, and 4

Now that we have decided what the best distribution to use is, we will fit the model to the data from Experiment 2. 

```{r glmm-compute-post-234}

# m_exp2_nrl <- readRDS("models/exp_2_nrl.models")
# m_exp2_log <- readRDS("models/exp_2_log.models")
m_exp2_sft <- readRDS("models/exp_2_sft.models")
# m_exp3_nrl <- readRDS("models/exp_3_nrl.models")
# m_exp3_log <- readRDS("models/exp_3_log.models")
m_exp3_sft <- readRDS("models/exp_3_sft.models")
# m_exp4_nrl <- readRDS("models/exp_4_nrl.models")
# m_exp4_log <- readRDS("models/exp_4_log.models")
m_exp4_sft <- readRDS("models/exp_4_sft.models")

```

### Use these models to compute $D$

note, remove ` subset = 1:1000` when we've re-ran models with equal number of 
samples! (in the `extract_fixed_slopes_from_model()` function)

```{r compute-D-1, fig.cap="Posterior estimates for $D$."}
slopes1 <- extract_fixed_slopes_from_model(m_exp1_sft)
slopes2 <- extract_fixed_slopes_from_model(m_exp2_sft)
slopes3 <- extract_fixed_slopes_from_model(m_exp3_sft)
slopes4 <- extract_fixed_slopes_from_model(m_exp4_sft)

bind_rows(
  slopes1 %>% mutate(exp = "Experiment 1"),
  slopes3 %>% mutate(exp = "Experiment 3")) %>%
  ggplot(aes(x= D, fill = d_feature)) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~exp, nrow = 2)
  
```

## Estimating model parameters

### $D$ for compound feature distractors

```{r predict-D-2, fig.cap = "Estimating D.", fig.height = 4}

Dp_samples <- bind_rows(
   get_Dp_samples(2, d, slopes1, slopes2),
   get_Dp_samples(4, d, slopes3, slopes4))


Dp_lines <- get_Dp_lines(Dp_samples)

plot_Dp_lines(Dp_lines)

rm(slopes1, slopes2, slopes3, slopes4)

```

Compute $R^2$ for each method

```{r}

get_D_R2 <- function(ii) {

 my_lm <- lm(De ~ Dp,
             filter(df, iter == ii))
 
   r2 <- summary(my_lm)$r.squared
   intercept <- my_lm$coefficients[1]
   slope <- my_lm$coefficients[2]
   
  return(tibble(r2 = r2, c = intercept, m = slope))
}


d_r2 <- tibble(method = as.character(),
               stat = as.character(),
               value = as.numeric(),
               .lower = as.numeric(),
               .upper = as.numeric())

for (meth in unique(Dp_samples$method)) {
  
  df <- filter(Dp_samples, method == meth)
  df_r2 <- map_df(unique(df$iter), get_D_R2)
  
  df_r2 %>% 
    pivot_longer(c(r2, c, m), names_to = "stat", values_to = "value") %>%
         group_by(stat) %>%  mean_hdci(.width = 0.97) %>%
    select(-.width, -.point, -.interval) %>%
    mutate(method = meth) -> df_r2
      
     d_r2 <- bind_rows(d_r2, df_r2)
     
     rm(df_r2)
}

knitr::kable(d_r2, digits = 3)

rm(df, r2, d_r2)

```

### Variance!

As we are using multi-level models to describe the whole distribution of reaction times we aslo need to provide a $\sigma$ and a sd(Intercept). 


Random intercepts look similar:

```{r}
VarCorr(m_exp1_sft)$p_id$sd
VarCorr(m_exp2_sft)$p_id$sd
```

Residual variance looks similar, although exp2 is lower that exp 1. 

```{r}
VarCorr(m_exp1_sft)$residual$sd
VarCorr(m_exp2_sft)$residual$sd
```


Seems legit for now to model Exp2 using the variances from Exp1 :)

## Predicting Reaction Times

```{r gen-predictions, fig.width = 10, fig.height = 10, cache=TRUE}
# in order to predict reaction times, we will specify a new version of our model
# It is a little bit hacky, but we can feed the predicted values for D into the 
# brms model as a prior, and then use that to simulate new trials.  

# first, summarise our Dp samples to give mu and sigma.
 Dp_samples %>%
   group_by(exp_id, d_feature, method) %>%
  summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
  mutate(d_feature = as_factor(d_feature)) -> Dp_summary

# now define and run new model! 
meth = "orthog_contrast"

model_params <- set_up_predict_model(2, "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")

```

Note, this plot is for how we expect the average person to perform in experiment 2. 

```{r plot-exp2-predictions, fig.height = 6, fig.cap="reaction time predictions."}
plot_model_fits_rt(2, m_prt, y_limits = c(0.2, 0.8), n_row = 3, plot_type = "fitted")
```

Do an R2 for this!


```{r}
d %>%
  filter(
    exp_id == 2, N_T > 0) %>%
  mutate(
    d_feature = fct_drop(d_feature),
    p_id = fct_drop(p_id)) %>%
  ungroup() %>%
  modelr::data_grid(N_T = unique(filter(d, N_T>0)$N_T), d_feature) %>%
  add_fitted_draws(m_prt, re_formula = NA, scale = "response", n = 500) -> d_samples

d %>%
  filter(
    exp_id == 2, N_T > 0) %>%
  mutate(
    d_feature = fct_drop(d_feature),
    p_id = fct_drop(p_id)) %>%
  ungroup() %>% 
  group_by(N_T, d_feature, p_id) %>%
  summarise(mean_rt = exp(mean(log(rt))), .groups = "drop") %>%
  group_by(N_T, d_feature) %>%
  summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
  left_join(d_samples, by = c("N_T", "d_feature")) -> d_samples
    
    
r2 <- vector()
    
i <- 0
for (draw in unique(d_samples$.draw)) {
  i <- i + 1
  ddraw <- filter(d_samples, .draw == draw)
  r2[i] <-   summary(lm(mean_rt ~ .value, ddraw))$r.squared
}

 hdci(r2, 0.97)      

```

Attempting plots for unknown participant! 

```{r plot-exp2-predictions-new-person, fig.height = 6, fig.cap="reaction time predictions."}
plot_model_fits_rt(2, m_prt, y_limits = c(0, 2), n_row = 3, plot_type = "predicted")
```

Does Bayes_R2 work on this?

```{r}
bayes_R2(m_prt)
```

# Power Analyis for Planned Studies

What do the results look like if:

1) the same people do all parts of the study, and there is a correlation between tasks
2) We reduce the number of trials down to 96 per condition. 


## Pretend the original experiment was within subjects!


rename participants to pretend that we have a between subjects measure!

```{r}

d %>% 
  select(-exp_id) %>% 
  separate(p_id, c("exp_id", "p_id"), "-") %>%
  mutate(p_id = paste(p_id, exp_id)) -> d

shuffle_noise = 0
map_dfr(unique(d$exp_id), rank_order_people, shuffle_noise = shuffle_noise) %>%
  left_join(d, by = "p_id")  %>%
  mutate(exp_id = parse_number(exp_id)) -> dr_no_shuffle 

dr_no_shuffle %>% group_by(ps_id, exp_id) %>% summarise(m_rt = median(rt), .groups = "drop") %>% 
  pivot_wider(names_from = "exp_id", values_from = "m_rt") %>%
  ggplot(aes(x = `1`, y = `2`)) + geom_point(colour = "cyan")  + 
  coord_fixed() -> plt_no_shuffle

shuffle_noise = 0.10
map_dfr(unique(d$exp_id), rank_order_people, shuffle_noise = shuffle_noise) %>%
  left_join(d, by = "p_id") %>%
  mutate(exp_id = parse_number(exp_id)) -> dr_shuffle 

dr_shuffle %>% group_by(ps_id, exp_id) %>% summarise(m_rt = median(rt), .groups = "drop") %>% 
  pivot_wider(names_from = "exp_id", values_from = "m_rt") %>%
  ggplot(aes(x = `1`, y = `2`)) + geom_point(colour = "cyan") + 
  coord_fixed() -> plt_shuffle

plt_no_shuffle + plt_shuffle
```

We now calculate our assumed "groundtruth"

```{r, message=FALSE, cache=TRUE}
# 
# 
# bayes_corr_subsample(dr_no_shuffle) 
# bayes_corr_subsample(dr_no_shuffle, 6) 
# 
# 
# bayes_corr_subsample(dr_shuffle) 
# bayes_corr_subsample(dr_shuffle, 6) 

# save the subsampled version:

dr_shuffle %>% group_by(p_id, exp_id, d_feature, N_T) %>%
      sample_n(6) %>%
      ungroup() -> dr_shuffle_ss 

write_csv(dr_shuffle_ss, "models/ss_data.csv")


```

If we now rerun the shifted-lognormal model on this dataset (Experiment 1 only) we can investigate how well we can predict each individual participant's performance in Experiment 2. 


## Sample 6 trials per condition


```{r, fig.height = 10}
# summary(d)
# 
# d %>% group_by(p_id, d_feature, N_T) %>%
#   slice_sample(n = 6) -> dss
# 
# d <- dss
# 
# summary(d)
# 
# mdl_inputs_log <- set_up_model(1, "lognormal")
# power_mdl1_log <- run_model(mdl_inputs_log, ppc = "no")
# 
# md_inputs_log <- set_up_model(2, "lognormal")
# power_mdl2_log <- run_model(mdl_inputs_log, ppc = "no")
# 
# mdl_inputs_log <- set_up_model(3, "lognormal")
# power_mdl3_log <- run_model(mdl_inputs_log, ppc = "no")
# 
# mdl_inputs_log <- set_up_model(4, "lognormal")
# power_mdl4_log <- run_model(mdl_inputs_log, ppc = "no")
```


```{r}

# plot_model_fits_rt(1, power_mdl1_log, plot_type = "fitted")
```


```{r compute-D-1-power, fig.cap="Posterior estimates for $D$."}
# slopes1 <- extract_fixed_slopes_from_model(power_mdl1_log)
# slopes3 <- extract_fixed_slopes_from_model(power_mdl3_log)
# 
# bind_rows(
#   slopes1 %>% mutate(exp = "Experiment1"),
#   slopes3 %>% mutate(exp = "Experiment 3")) %>%
#   ggplot(aes(x= D, fill = d_feature)) + 
#   geom_density(alpha = 0.5) +
#   facet_wrap(~exp, nrow = 2)
  
```


## Estimating model parameters

### $D$ for compound feature distractors

```{r predict-D-2-power}
# slopes2 <- extract_fixed_slopes_from_model(m_exp2_log)
# slopes4 <- extract_fixed_slopes_from_model(m_exp4_log)
# 
# 
# Dp_samples <- bind_rows(
#   get_Dp_samples(2, d, slopes1, slopes2),
#   get_Dp_samples(4, d, slopes3, slopes4))
# 
# Dp_lines <- get_Dp_lines(Dp_samples)
# knitr::kable(Dp_lines, digits = 2)
# plot_Dp_lines(Dp_lines)
# 
# ggsave("../plots/recreate_log_normal_fig_4.pdf", width = 8, height = 2.5)
# 
# rm(slopes1, slopes2)


```


# Enviroment Details, packages and Vesion Numbers


```{r session-info}
sessionInfo()
```