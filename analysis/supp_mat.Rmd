---
title: "Supplementary Materials"
author: "ADF Clarke and AE Hughes"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

```

# Setup and Data Import

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
```

```{r}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

We will import data from all experiments. While we're at it, we will remove error trials.

```{r import-data}
source("scripts/import_and_tidy.R")
summary(d)
```

# Computational Replication of Buetti et al (2019)

Before doing anything else (i.e., new), we want to confirm that we can replicate the original analysis. This section walks through the original analysis.

```{r}
# functions used for the analysis re-implementation
source("scripts/reimplementation.R")
```

## Calculating $D$

Calculate $D_e$ (the empirical slopes) for each condition in each experiment.

```{r}
De <- map_dfr(unique(d$exp_id), calc_D_per_feature)
```

## Predicting $D$

We can now use the values of $D$ calculated above to predict values of $D$ ($D_p$) for all experiments 2x and 4x (referred to as $D_{c,s}$ in the main manuscript).

```{r}
exps_to_predict <- c("2a", "2b", "2c", "4a", "4b", "4c")
Dp <- map_df(exps_to_predict, gen_exp_predictions, De)
```
 
Recreate the scatter plots from Buetti et al (2019), Figure 4.

```{r replicating-D-plot, fig.cap="Computational replication of Figure 4 (top row) from Buetti et al (2019)."}
left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(
    cols = c(`best feature`, `orthog. contrast`, collinear),
    values_to = "Dp",
    names_to = "method") %>%
  mutate(method = fct_relevel(method, "best feature", "orthog. contrast")) %>%
  ggplot(aes(x = Dp, y = D)) +
  geom_point( color = "yellow1") + 
  geom_abline(linetype = 2, colour = "cyan") +
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  # coord_cartesian(xlim = c(0, 80), ylim = c(0, 80)) + 
  facet_wrap(~ method) + 
  scale_x_continuous("predicted D") + 
  scale_y_continuous("empirical D")
```

Now we compute $R^2$ to get a measure of how well $D_p$ predict the $D_e$, calculated for each method and each set of experiments, as well as an overall measure. 

```{r}
Dp_tmp <- left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(-c(exp_id, d_feature, D), names_to = "method", values_to = "Dp")

df_r2 <- tibble(exp_id = as.character(), method = as.character(), r2 = as.numeric())

for (e_id in exps_to_predict) {
  for (meth in unique(Dp_tmp$method)) {
    
    df <- filter(Dp_tmp, method == meth, exp_id == e_id)
    r2 <- summary(lm(D ~ Dp, data = df))$r.squared
    
    df_r2 <- add_row(df_r2, 
                      exp_id = paste("Exp", e_id), method = meth, r2 = r2)
  }  
}

 for (meth in unique(Dp_tmp$method)) {
  df <- filter(Dp_tmp, method == meth)
  r2 <- summary(lm(D ~ Dp, data = df))$r.squared
  # print(meth)
  # print(summary(lm(D ~ Dp, data = df))$r.squared)
  df_r2 <- add_row(df_r2, 
                 exp_id = "all", method = meth, r2 = r2)
 }

df_r2 %>% pivot_wider(method, names_from = "exp_id", values_from = "r2") %>%
  knitr::kable(digits =3)

rm(df_r2, Dp_tmp)

```

The values in the *all* column match those given in Figure 4 (top) (Buetti et al, 2019).

## Predicting Reaction Times

$L$ indicates the number of distractor types present in the display, $N_T$ is the total number of distractors, $N_i$ is the number of distractors of type $i$, $D_j$ indicates the logarithmic slope parameters associated with distractor of type $j$ (organized from smallest $D_1$ to largest $D_L$). Note that the $D$ parameter is the one that increases with increasing target-distractor similarity.

The constant a represents the reaction time when the target is alone in the display. Inter-item interactions were indexed by the multiplicative factor $\beta$. Finally, the index function $1_{[2, \infty)} (j)$ indicates that the sum over Ni only applies when there are at least two different types of lures in the display $(j > 1)$. When $j = 1$, the second sum is zero.

```{r pred-rt-replication, fig.width = 4.5, fig.asp=1, fig.cap="Computational Replication of RT predictions: Figure 4 (bottom right) from Buetti et al (2019)"}

rt_pred <- map_dfr(exps_to_predict, predict_rt)

d %>% filter(exp_id %in% exps_to_predict) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) %>% 
	ggplot(aes(x = p_rt, y = mean_rt)) + 
  geom_point(color = "yellow1", alpha = 0.5) + 
  geom_abline(linetype = 2, colour = "cyan") + 
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  scale_x_continuous("predicted reaction time (ms)") +
  scale_y_continuous("empirical mean reaction time (ms)")

```

As a final check that we correctly understand the TCS model and have reimplemented it correctly, we can calculate the $R^2$ between predicted and empirical reaction times. 

```{r}
d %>% filter(exp_id %in% exps_to_predict, N_T > 0) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) -> d_corr
```

The $R^2=$ `r round(summary(lm(mean_rt ~ p_rt, d_corr))$r.squared,2)`, matching the value given in Buetti et al (2019).

```{r tidy-up}
# remove variables we no longer need
rm(De, Dp, rt_pred, exps_to_predict, 
   calc_D_per_feature, extract_a_value, predict_D_overall, gen_exp_predictions, extract_D, predict_rt, d_corr)
```

# Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use lognormal and shifted-lognormal distributions for modelling reaction times, This allows us to avoid ever predicting impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milliseconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
- Remove the bottom and top 1% of data
  
```{r}
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4 
# remove outlier RTs
d <- our_changes_to_data(d)
```

## Measuring $D$ from Empirical Data

The models discussed here have been fit in the `fit_models.R` script. In order to validate our choice of distribution, we will run our analysis using a (i) normal, (ii) lognormal, and (iii) shifted-lognormal model. Additionally, we will also consider a version of the shifted-lognormal model that is linear in $N_t$ (while all the other models are loglinear in $N_t$).

### Prior Predictions

We can take the prior model, and then use it to compute our prior predictions.

```{r glmm-prior-sample}

  prior_model_nrl <- readRDS("models/prior_nrl.models")
  prior_model_log <- readRDS("models/prior_log.models")
  prior_model_sft <- readRDS("models/prior_sft.models")
```

```{r plt-prior, fig.height=2.5, fig.cap="Sample Prior predictions for reaction time and log(N+1) for the normal model (left), lognormal model (centre) and shifted-lognormal model (right)."}
  
plt_nrl <- plot_model_fits_rt(1, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "blue")
plt_log <- plot_model_fits_rt(1, prior_model_log, y_limits = c(0, 10), feature2plot = "blue")
plt_sft <- plot_model_fits_rt(1, prior_model_sft, y_limits = c(0, 10), feature2plot = "blue")
                             
plt_nrl + plt_log + plt_sft

# tidy up, we no longer need to keep hold of these models and plots
rm(
 prior_model_nrl, 
 prior_model_log, 
 prior_model_sft, 
 plt_nrl, plt_log, plt_sft)
```

### Fit Model and Posterior Predictions For Experiment 1

```{r glmm-compute-post-1}

m_exp1_nrl <- readRDS("models/exp_1_nrl.models")
m_exp1_log <- readRDS("models/exp_1_log.models")
m_exp1_sft <- readRDS("models/exp_1_sft.models")
m_exp1_sft_nolog <- readRDS("models/exp_1_sft_nolog.models")
```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt-post, fig.height=10, fig.cap="Posterior predictions for the reaction time for the average participant and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$."}

plt_nrl <- plot_model_fits_rt(1, m_exp1_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(1, m_exp1_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(1, m_exp1_sft, plot_type = "fitted")
plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")

plt_nrl / plt_log / plt_sft / plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
```

We can see that all of our models give very similar relationship between $N_T$ and mean reaction time. In the next plot, we look at the model's predictions for the distribution of reaction times. 


```{r plt-post-re, fig.height=10, fig.cap="Posterior predictions for reaction time distributions and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$."}

plt_nrl <- plot_model_fits_rt(1, m_exp1_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(1, m_exp1_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(1, m_exp1_sft, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))

plt_nrl / plt_log / plt_sft / plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
```

### Model Comparison

Load the model weights to decide on best model...

```{r model-weights, cache=TRUE}

loo_m_exp1_nrl <- readRDS("models/loo_m_exp1_nrl.rds")
loo_m_exp1_log <- readRDS("models/loo_m_exp1_log.rds")
loo_m_exp1_sft <- readRDS("models/loo_m_exp1_sft.rds")
loo_m_exp1_sft_nolog <- readRDS("models/loo_m_exp1_sft_nolog.rds")

loo_list <- list(loo_m_exp1_nrl, loo_m_exp1_log, loo_m_exp1_sft, loo_m_exp1_sft_nolog)

tibble(model = c("normal", "lognormal", "shifted-lognormal", "linear in $N_T$"),
       weight = as.double(loo_model_weights(loo_list))) %>% 
  knitr::kable()
```

These model weights strongly suggest that the shifted-lognormal model gives a better prediction than the lognormal or normal models. It also confirmed that we do want to keep the model loglinear in $N_T$.

We will need to use the `bridge_sampler()` function later on, so let's use it here and verify that it gives the same result as `loo()`.

```{r}
bs_exp1_nrl <- bridge_sampler(m_exp1_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp1_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp1_sft, silent = TRUE)
bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)

tibble(model = c("normal", "lognormal", "shifted-lognormal", "linear in $N_T$"),
       weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft, bs_exp1_sft_nolog)) %>% 
  knitr::kable()

#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
```

Both methods give the same result, which is good news! From now on, we will only consider the shifted-lognormal model, as it outperforms the other models that we have considered. 

### Model diagnostics for shifted-lognormal model

The model diagnostics (Rhat values, trace plots) for our shifted-lognormal model seem okay, and are plotted below.
\tiny
```{r model_diagnostics, fig.height = 5, fig.cap = "Model diagnostics for the shifted-lognormal model."}
summary(m_exp1_sft)
plot(m_exp1_sft, pars = "^b_") 
```
\normalsize

### Fit Model and Posterior Predictions For Experiment 2, 3, and 4

Now that we have decided what the best distribution to use is, we will fit the model to the data from Experiment 2. 

```{r glmm-compute-post-234}
#load previously fitted models
m_exp2_sft <- readRDS("models/exp_2_sft.models")
m_exp3_sft <- readRDS("models/exp_3_sft.models")
m_exp4_sft <- readRDS("models/exp_4_sft.models")
```

### Use these models to compute $D$

Now we can compute $D_e$ by extracting the fixed effect slopes from the model for each experiment and condition.

```{r compute-D-1, fig.cap="Posterior estimates for $D$."}
slopes1 <- extract_fixed_slopes_from_model(m_exp1_sft)
slopes2 <- extract_fixed_slopes_from_model(m_exp2_sft)
slopes3 <- extract_fixed_slopes_from_model(m_exp3_sft)
slopes4 <- extract_fixed_slopes_from_model(m_exp4_sft)

bind_rows(
  slopes1 %>% mutate(exp = "Experiment 1"),
  slopes3 %>% mutate(exp = "Experiment 3")) %>%
  ggplot(aes(x= D, fill = d_feature)) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~exp, nrow = 2)
```

We can see that we have a posterior probability distribution for each type of distracter in both experiment 1 and 3. 

## Estimating model parameters

Now, we use the model fitted on experiment 1 (or 3) to predict the data in experiment 2 (or 4). I.e., can we predict $D_p$ for compound features based on the $D_e$ values for the related single features. 

### $D$ for compound feature distractors

Buetti et al (2019) considered three methods for calculating $D_p$: best feature, orthogonal contrast and collinear. We will use these three methods, and also a linear combination of these three.

```{r predict-D-2, fig.cap = "Estimating D, using four different calculation methods.", fig.height = 4}

Dp_samples <- bind_rows(
   map_dfr(c("2a", "2b", "2c"), get_Dp_samples, d, slopes1, slopes2),
   map_dfr(c("4a", "4b", "4c"), get_Dp_samples, d, slopes3, slopes4))

# get best possible linear fit of the various methods!
Dp_samples %>% 
  pivot_wider(
    c(exp_id, d_feature, iter, De), 
    names_from = method, values_from = Dp) -> d_lmer

# find mle best fit
m_lmer <- lme4::lmer(data = d_lmer, De ~ best_feature + orthog_contrast + collinear + (1|iter))

d_lmer %>% 
  mutate(linear_comb = predict(m_lmer)) %>%
  pivot_longer(
    c(best_feature, orthog_contrast, collinear, linear_comb), 
    names_to = "method", 
    values_to = "Dp") %>%
  mutate(method = fct_relevel(method, "linear_comb", after = Inf)) -> Dp_samples

rm(d_lmer, m_lmer)

Dp_lines <- get_Dp_lines(Dp_samples)
plot_Dp_lines(Dp_lines)

rm(slopes1, slopes2, slopes3, slopes4)

```

Compute $R^2$ for each method

```{r}

get_D_R2 <- function(ii) {

 my_lm <- lm(De ~ Dp,
             filter(df, iter == ii))
 
   R2 <- summary(my_lm)$r.squared
   intercept <- my_lm$coefficients[1]
   slope <- my_lm$coefficients[2]
   
  return(tibble(r2 = R2, c = intercept, m = slope))
}

d_r2 <- tibble(method = as.character(),
               stat = as.character(),
               value = as.numeric(),
               .lower = as.numeric(),
               .upper = as.numeric())

for (meth in unique(Dp_samples$method)) {
  
  df <- filter(Dp_samples, method == meth)
  df_r2 <- map_df(unique(df$iter), get_D_R2)
  
  df_r2 %>% 
    pivot_longer(c(r2, c, m), names_to = "stat", values_to = "value") %>%
         group_by(stat) %>%  mean_hdci(.width = 0.97) %>%
    select(-.width, -.point, -.interval) %>%
    mutate(method = meth) -> df_r2
      
     d_r2 <- bind_rows(d_r2, df_r2)
     
     rm(df_r2)
}

knitr::kable(d_r2, digits = 3)

rm(df, r2, d_r2)

```

### Variance!

As we are using multi-level models to describe the whole distribution of reaction times we also need to provide a $\sigma$ and a sd(Intercept). 


Random intercepts look similar:

```{r}
VarCorr(m_exp1_sft)$p_id$sd
VarCorr(m_exp2_sft)$p_id$sd
```

Residual variance looks similar, although Experiment 2 is lower than Experiment 1. 

```{r}
VarCorr(m_exp1_sft)$residual$sd
VarCorr(m_exp2_sft)$residual$sd
```

It seems possible to model Experiment 2 using the variances from Experiment 1.

## Predicting Reaction Times

In order to predict reaction times, we will specify a new version of our model.

We can feed the predicted values for $D$ into our `brms` model as a prior, and then use that to simulate new trials.

```{r gen-predictions, fig.width = 10, fig.height = 10, cache=TRUE, message=FALSE}

# first, summarise our Dp samples to give mu and sigma.

compute_rt_predictions <- function(meth) {
  Dp_samples %>%
    filter(method == meth) %>%
    group_by(exp_id, d_feature) %>%
    summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
    mutate(
      d_feature = as_factor(d_feature),
      method = meth) -> Dp_summary

  # now define and run new model! 
  
  model_params <- set_up_predict_model("2", "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
  m_prt <- run_model(model_params, ppc = "only")
    
  return(m_prt)
  
}

m_prt_best_feature <- compute_rt_predictions(meth = "best_feature")
m_prt_collinear <- compute_rt_predictions(meth = "collinear")
m_prt_orthog_contrast <- compute_rt_predictions(meth = "orthog_contrast")
m_prt_linear_transform <- compute_rt_predictions(meth = "linear_comb")

bs_bfeat <- bridge_sampler(m_prt_best_feature, silent = TRUE)
bs_orth <- bridge_sampler(m_prt_orthog_contrast, silent = TRUE)
bs_col <- bridge_sampler(m_prt_collinear, silent = TRUE)
bs_lint <- bridge_sampler(m_prt_linear_transform, silent = TRUE)

post_prob(bs_bfeat, bs_col, bs_orth)

post_prob(bs_bfeat,bs_col, bs_orth, bs_lint)  

rm(bs_bfeat,bs_col, bs_orth, bs_lint)
```

Note, this plot is for how we expect the average person to perform in experiment 2, using the orthogonal contrast combination method: 

```{r plot-exp2-predictions, fig.height = 6, fig.cap="Reaction time predictions for the average person for the orthogonal contrast method, predicting reaction times in Experiment 2."}

m_prt <- m_prt_orthog_contrast
plot_model_fits_rt(2, m_prt_orthog_contrast, y_limits = c(0.2, 0.8), n_row = 3, plot_type = "fitted")
```

Show how intercept varies in sub-experiment:

```{r, message = FALSE, warning = FALSE}

d %>% filter(N_T == 0, exp_id == 2) %>%
  separate(p_id, into = c("sub_exp", "person")) %>%
  group_by(sub_exp, person) %>%
  summarise(mean_rt = exp(mean(log(rt)))) %>%
  ggplot(aes(x = sub_exp, y= mean_rt)) + geom_boxplot()

```

Plots for unknown participants (again, using the orthogonal contrast model):

```{r plot-exp2-predictions-new-person, fig.height = 6, fig.cap="Reaction time distribution predictions for the orthogonal contrast method, predicting reaction times in Experiment 2."}
plot_model_fits_rt(2, m_prt_orthog_contrast, y_limits = c(0, 2), n_row = 3, plot_type = "predicted")
```


# Power Analyis for Planned Studies

Our sensitivity analysis is based around the width of the 97% HPDI when estimating D~blue. 

```{r, eval = FALSE}

d_power <- filter(d, exp_id == 1, d_feature == "blue")

my_f <- bf(rt ~ 1 + log(N_T+1) + (1|p_id), 
           ndt ~ 1 + (1|p_id))

orig_model <- readRDS("models/exp_1_sft.models")

# HPDI width for original model
get_orig_w <- function(d) {
  
  model_params <- set_up_model(1, "shifted_lognormal")
  model_params$my_formula <- my_f
  model_params$df <- d_power
  m <- run_model(model_params, ppc = "no")
  h <- hdci(posterior_samples(m, "logN_TP1"), 0.97)
  w_orig <- h[2] - h[1]
  return(w_orig)
  
}

w_orig <- get_orig_w(d)

# Take subsample of trials and people and fit model
get_hdpi_for_subsample <- function(n) {
  
  # simulate dataset of required size from original model
  d_power %>% modelr::data_grid(N_T, d_feature, p_id = 1:samples$peeps[n])  %>%
    add_predicted_draws(orig_model, re_formula = NULL, allow_new_levels = TRUE, n = samples$trials[n]) %>%
    ungroup() %>% 
    select(p_id, d_feature, N_T, trial = ".draw", rt = ".prediction") -> d_sim
  
  # fit new model to simualated data!
  model_params <- set_up_model(1, "shifted_lognormal")
  model_params$my_formula <- my_f
  model_params$df <- d_sim
  m <- run_model(model_params, ppc = "no")
  h <- hdci(posterior_samples(m, "logN_TP1"), 0.97)
  w <- h[2] - h[1]
  return(w)
  
}

# Numbers of trials and people we will simulate
samples <- modelr::data_grid(d, 
                             trials = c(2,4,6,8,10,12,14,16,20,24,32,40), 
                             peeps= c(20, 40, 80, 160))

# Run simulation
w <- map_dbl(1:nrow(samples), get_hdpi_for_subsample)
samples$w <- w

# Calculating HDPI width as a proportion of the slope
d_mean <- 0.18
o_prop <- w_orig/d_mean
samples$w_prop <- w/d_mean
samples$peeps <- factor(samples$peeps)

# Filtering out any problematic fits
samples <- samples %>%
  filter(w_prop < 1)

# Making a power plot
plt_power <- ggplot(samples, aes(trials, w_prop, colour = peeps)) + geom_point() + 
  geom_line() + geom_hline(yintercept = o_prop, linetype = "dashed") +
  annotate("text", label = "X", x = 40, y = 0.14683205, size = 6) +
  theme_bw() + xlab("Number of samples") + 
  ylab("HDPI width as a proportion of slope")

```

# Enviroment Details, packages and Version Numbers


```{r session-info}
sessionInfo()
```