---
title: "Implementing Buetti et al(2019)"
author: "ADF Clarke"
date: "24/08/2020"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)

source("scripts/reimplementation.R")
source("scripts/our_functions.R")

refit_models = FALSE

exps_to_predict = c("2a", "2b", "2c", "4a", "4b", "4c")
```
# Data Import and Overview

## Importing

We will import all experiments. While we're at it, we will remove error trials and very very short responses.

*What about very very long RTs? I'm not sure if there is a good reason to, or obvious cut off? Unlike for short Rts, in which values == 0 are mathematically impossible, and values <10ms are implausible. 
  
```{r import-data}
source("scripts/import_and_tidy.R")
 # remove error trials and very very short responses
d <- filter(d, error == 0, rt > 0.01)
```

## Overview: some summary statisitcs

```{r rt_exp_1b_hist, fig.cap="Histogram showing indivdidual differences in median RT in Experiment 1b."}
d %>% group_by(exp_id, p_id, d_feature) %>%
  summarise(median_rt = median(rt)) %>%
  filter(exp_id == "1b") %>%
  ggplot(aes(x = median_rt, fill = d_feature)) + 
  geom_histogram(bins = 10, colour = "black") + 
  facet_wrap(~d_feature) + 
  scale_x_continuous("median reaction time") +
  theme_bw()

ggsave("../plots/histograms_of_rt.pdf", width = 6, height = 3)
```

# Computational Replication of Buetti et al (2019)

Before doing anything else (i.e., new), we want to confirm that we can replicate the original analysis.

## Calculating $D$

Calculate $D_e$ for each condition in each experiment. 

```{r}
De <- map_dfr(unique(d$exp_id), calc_D_per_feature, d)
```

## Predicing $D$

We can now predict values of $D$ for all experiments 2x and 4x. 

```{r}
Dp <- map_df(c("2a", "2b", "2c", "4a", "4b", "4c"), gen_exp_predictions, De)
```
 
Now, recreate the scatter plots from Buetti et al (2019), Figure 4.

```{r replicating_D_plot, fig.cap="Computational replication of Figure 4 (top row) from Buetti et al (2019)."}
left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(
    cols = c(`best feature`, `orthog. contrast`, collinear),
    values_to = "Dp",
    names_to = "method") %>%
  mutate(method = fct_relevel(method, "best feature", "orthog. contrast")) %>%
  ggplot(aes(x = Dp, y = D)) +
  geom_point() + 
  geom_abline(linetype = 2) +
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  coord_cartesian(xlim = c(0, 80), ylim = c(0, 80)) + 
  facet_wrap(~ method) + 
  see::theme_lucid() + 
  scale_x_continuous("predicted D") + 
  scale_y_continuous("empirical D")
```

## Predicting Reaction Times

$L$ indicates the number of distractor types present in the display, $N_T$ is the total number of distractors, $N_i$ is the number of distractors of type $i$, $D_j$ indicates the logarithmic slope parameters associated with distractor of type $j$ (organized from smallest $D_1$ to largest $D_L$). Note that the $D$ parameter is the one that increases with increasing target-distractor similarity.

The constant a represents the reaction time when the target is alone in the display. Inter-item interactions were indexed by the multiplicative factor $\beta$. Finally, the index function $1_{[2, \infty)} (j)$ indicates that the sum over Ni only applies when there are at least two different types of lures in the display $(j > 1)$. When $j = 1$, the second sum is zero.

```{r pred_rt_replication, fig.width = 4, fig.cap="Computational Replication of RT predictions."}
exps2predict = c("2a", "2b", "2c", "4a", "4b", "4c")

rt_pred <- map_dfr(exps2predict, predict_rt)

d %>% filter(exp_id %in% exps2predict) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) %>% 
	ggplot(aes(x = p_rt, y = mean_rt)) + 
  geom_point(alpha = 0.5) + 
  geom_abline() + 
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  see::theme_lucid() +
  scale_x_continuous("predicted reaction time (ms)") +
  scale_y_continuous("empirical mean reaction time (ms)")

# Exporting some data in case we need to sanity check
d %>% filter(exp_id %in% exps2predict) %>%
  group_by(exp_id, p_id, d_feature, N_T) %>%
  summarise(mean_rt = mean(rt), .groups = "drop") %>%
  group_by(exp_id,  d_feature, N_T) %>%
  summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
  left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) -> d_out
```

<TODO> show RT predictions for the other two methods?

# Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use a lognormal distribution for modelling reaction times, This allows us to avoid ever predicing impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milli-seconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  
## Measuring $D$ from Empirical Data

We'll make a few minor changes to the data:
  - Switch from ms to seconds
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
```{r}
d %>% mutate(
  rt = rt/1000,
  exp_id = parse_number(exp_id)) -> d
```

### Prior Predictions

We can take the prior model, and then use it to compute our prior predictions!

```{r glmm-prior-sample, cache=TRUE}
prior_model_nrl <- fit_glmm_to_an_exp("1", d, ppc = "only", "normal")
prior_model_log <- fit_glmm_to_an_exp("1", d, ppc = "only", "lognormal")
prior_model_sft <- fit_glmm_to_an_exp("1", d, ppc = "only", "shifted")

```

```{r plt_prior, fig.height=8, fig.cap="Sample Prior predictions for reaction time and log(N+1)."}
plt_nrl <- plot_model_fits_ex(d, 1, prior_model_nrl)
plt_log <- plot_model_fits_ex(d, 1, prior_model_log)
plt_sft <- plot_model_fits_ex(d, 1, prior_model_sft)
                            
plt_nrl / plt_log / plt_sft

```

```{r remove-prior-models}
rm(
  prior_model_nrl, prior_model_log, prior_model_sft, 
  plt_nrl, plt_log, plt_sft)
```

### Fit Model and Posterior Predictions For Experiment 1

```{r}

if (refit_models)
{
  m_exp1_nrl <- fit_glmm_to_an_exp(1, d, ppc = "no", fam = "normal")
  saveRDS(m_exp1_nrl, "exp_1_nrl.models")
  
  m_exp1_log <- fit_glmm_to_an_exp(1, d, ppc = "no", fam = "lognormal")
  saveRDS(m_exp1_log, "exp_1_log.models")
  
  m_exp1_sft <- fit_glmm_to_an_exp(1, d, ppc = "no", fam = "shifted")
  saveRDS(m_exp1_sft, "exp_1_sft.models")
} else {
  
  m_exp1_nrl <- readRDS("exp_1_nrl.models")
  m_exp1_log <- readRDS("exp_1_log.models")
  m_exp1_sft <- readRDS("exp_1_sft.models")
  
}

# m_exp1_nrl <- add_criterion(m_exp1_nrl, c("loo"))
# m_exp1_log <- add_criterion(m_exp1_log, c("loo"), moment_match = TRUE)

```

Calculate model weights to decide on best model...

```{r}

# model_weights(m_exp1_nrl, m_exp1_log)
```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt_post, fig.height=8, fig.cap="Sample Prior predictions for reaction time and log(N+1)."}

plt_nrl <- plot_model_fits_ex(d, 1, m_exp1_nrl)
plt_log <- plot_model_fits_ex(d, 1, m_exp1_log)
plt_sft <- plot_model_fits_ex(d, 1, m_exp1_sft)

plt_nrl / plt_log / plt_sft
```


### Fit Model and Posterior Predictions For Experiment 2

Now that we have decided what the best distribution to use is, we will fit the model to the data from Experiment 2. 

```{r}

if (TRUE)
{
  m_exp2_log <- fit_glmm_to_an_exp(2, d, ppc = "no", fam = "lognormal")
  m_exp3_log <- fit_glmm_to_an_exp(3, d, ppc = "no", fam = "lognormal")
  m_exp4_log <- fit_glmm_to_an_exp(4, d, ppc = "no", fam = "lognormal")
  saveRDS(m_exp2_log, "exp_2_log.models")
  saveRDS(m_exp3_log, "exp_3_log.models")
  saveRDS(m_exp4_log, "exp_4_log.models")

} else {

  # m_exp2_log <- readRDS("exp_2_log.models")
  
}

```

### Use these models to compute $D$

```{r}
slopes1 <- extract_fixed_slopes_from_model(m_exp1_log)
# slopes2 <- extract_fixed_slopes_from_model(m_exp2_log)

```

```{r}
ggplot(slopes1, aes(x= D, fill = d_feature)) + geom_density(alpha = 0.25)

```


```{r}
#De <- map_df(
#  1:length(my_models_idt),
#  extract_fixed_slopes_from_model,
#  my_models_idt, df = d)

#ggplot(De, aes(x = D, fill = d_feature)) +
#  geom_density(alpha = 0.333) +
#  facet_wrap(~ exp_id, ncol = 5) +
#  theme_bw()

#ggsave("../plots/buetti2019_bayesian_fits.pdf", width = 8, height = 3)
```

## Estimating $D$ for compound feature distractors

```{r}

#Dp_samples <- map_df(exps_to_predict, get_Dp_samples, d)

# add in average D (of collinear and orthogonal)

#Dp_samples %>% pivot_wider(names_from = method, values_from = Dp) %>%
#  group_by(iter, exp_id, d_feature) %>%
#  mutate(mean_method = mean(c(orthog_contrast, collinear))) %>%
#  pivot_longer(c(best_feature, orthog_contrast, collinear, mean_method), names_to = "method", values_to = "Dp") -> Dp_samples


# Dp_samples %>%
#   group_by(exp_id, d_feature, method) %>%
#   mean_hdci(Dp, De) %>%
#  ggplot(aes(x = Dp, y = De)) +
#  geom_abline(linetype = 2) +
#  geom_point() +
#  facet_wrap(~method, nrow = 1) + theme_bw() +
#  geom_linerange(aes(ymin = De.lower, ymax = De.upper), alpha = 0.5) +
#  geom_linerange(aes(xmin = Dp.lower, xmax = Dp.lower), alpha = 0.5) +
#  geom_smooth(method = lm, colour = "pink")

#ggsave("recreate_log_normal_fig_4.pdf", width = 8, height = 2.5)

```

## Which slope is closer to 1?

```{r}
#slopes_err <- function(ii, df)  {

#  d_itr = filter(df, iter == ii)

#  beta = summary(lm(data = d_itr, De ~ (Dp):(0 + method)))$coefficients[, 1]
#  beta_err = abs(1 - beta)

#  return(beta_err)
#}


#beta_err <- map_df(unique(Dp_samples$iter), slopes_err, Dp_samples)
#names(beta_err) <- str_remove(names(beta_err), 'Dp:method')

# beta_err %>% pivot_longer(1:4, names_to = "method", values_to = "abs_res") %>%
#   ggplot(aes(x = abs_res, fill = method)) + geom_density(alpha = 0.33)

# beta_err %>% select(-best_feature) %>%
#   mutate(difference = orthog_contrast - collinear) %>%
#   ggplot(aes(x = difference)) + geom_density()

#  beta_err %>% select(-best_feature) %>%
#   mutate(difference = mean_method - collinear) -> x

#  mean(x$difference > 0)

```

## Predicting Reaction Times

```{r, fig.width = 10, fig.height = 10, cache=TRUE}

# Dp_samples %>%
#   group_by(exp_id, d_feature, method) %>%
#  summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop")-> Dp_summary

#meth <- "mean_method"

#d_prt <- map_df(exps_to_predict, predict_rt_b, meth, Dp_summary, d)
```


```{r}

#d_rt <- d %>% filter(N_T > 0) %>%
#  group_by(p_id, exp_id, d_feature, N_T) %>% summarise(
#    mean_log = MASS::fitdistr(rt, densfun = "log-normal")$estimate["meanlog"],
#    mean_rt = mean(rt)) %>%
#   group_by(exp_id, d_feature, N_T) %>% summarise(rt = exp(median(mean_log))) %>%
# right_join(d_prt, by = c("exp_id", "d_feature", "N_T"))

#ggplot(data = d_rt, aes(x = rt, y = .value)) +
#  geom_abline(linetype = 2) +
#  geom_point() + geom_errorbar(aes(ymin = .lower, ymax = .upper))+
#  theme_bw()



#print(mean(abs(d_rt$rt - d_rt$.value)))

```
# Power Analyis for Planned Studies
