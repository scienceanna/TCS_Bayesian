---
title: "Implementing Buetti et al(2019)"
author: "ADF Clarke"
date: "24/08/2020"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)

source("scripts/reimplementation.R")
source("scripts/our_functions.R")

exps_to_predict = c("2a", "2b", "2c", "4a", "4b", "4c")
```
# Data Import and Overview

## Importing

We will import all experiments. While we're at it, we will remove error trials and very very short responses.

*What about very very long RTs? I'm not sure if there is a good reason to, or obvious cut off? Unlike for short Rts, in which values == 0 are mathematically impossible, and values <10ms are implausible. 
  
```{r import-data}
source("scripts/import_and_tidy.R")
 # remove error trials and very very short responses
d <- filter(d, error == 0, rt > 0.01)
```

## Overview: some summary statisitcs

```{r rt_exp_1b_hist, fig.cap="Histogram showing indivdidual differences in median RT in Experiment 1b."}
d %>% group_by(exp_id, p_id, d_feature) %>%
  summarise(median_rt = median(rt)) %>%
  filter(exp_id == "1b") %>%
  ggplot(aes(x = median_rt, fill = d_feature)) + 
  geom_histogram(bins = 10, colour = "black") + 
  facet_wrap(~d_feature) + 
  scale_x_continuous("median reaction time") +
  theme_bw()

ggsave("../plots/histograms_of_rt.pdf", width = 6, height = 3)
```

# Computational Replication of Buetti et al (2019)

Before doing anything else (i.e., new), we want to confirm that we can replicate the original analysis.

## Calculating $D$

Calculate $D_e$ for each condition in each experiment. 

```{r}
De <- map_dfr(unique(d$exp_id), calc_D_per_feature, d)
```

## Predicing $D$

We can now predict values of $D$ for all experiments 2x and 4x. 

```{r}
Dp <- map_df(c("2a", "2b", "2c", "4a", "4b", "4c"), gen_exp_predictions, De)
```
 
Now, recreate the scatter plots from Buetti et al (2019), Figure 4.

```{r replicating_D_plot, fig.cap="Computational replication of Figure 4 (top row) from Buetti et al (2019)."}
left_join(Dp, De, by = c("exp_id", "d_feature")) %>%
  pivot_longer(
    cols = c(`best feature`, `orthog. contrast`, collinear),
    values_to = "Dp",
    names_to = "method") %>%
  mutate(method = fct_relevel(method, "best feature", "orthog. contrast")) %>%
  ggplot(aes(x = Dp, y = D)) +
  geom_point() + 
  geom_abline(linetype = 2) +
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  coord_cartesian(xlim = c(0, 80), ylim = c(0, 80)) + 
  facet_wrap(~ method) + 
  see::theme_lucid() + 
  scale_x_continuous("predicted D") + 
  scale_y_continuous("empirical D")
```

## Predicting Reaction Times

$L$ indicates the number of distractor types present in the display, $N_T$ is the total number of distractors, $N_i$ is the number of distractors of type $i$, $D_j$ indicates the logarithmic slope parameters associated with distractor of type $j$ (organized from smallest $D_1$ to largest $D_L$). Note that the $D$ parameter is the one that increases with increasing target-distractor similarity.

The constant a represents the reaction time when the target is alone in the display. Inter-item interactions were indexed by the multiplicative factor $\beta$. Finally, the index function $1_{[2, \infty)} (j)$ indicates that the sum over Ni only applies when there are at least two different types of lures in the display $(j > 1)$. When $j = 1$, the second sum is zero.

```{r pred_rt_replication, fig.width = 4, fig.cap="Computational Replication of RT predictions."}
exps2predict = c("2a", "2b", "2c", "4a", "4b", "4c")

rt_pred <- map_dfr(exps2predict, predict_rt)

d %>% filter(exp_id %in% exps2predict) %>%
	group_by(exp_id, p_id, d_feature, N_T) %>%
	summarise(mean_rt = mean(rt), .groups = "drop") %>%
	group_by(exp_id,  d_feature, N_T) %>%
	summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
	left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) %>% 
	ggplot(aes(x = p_rt, y = mean_rt)) + 
  geom_point(alpha = 0.5) + 
  geom_abline() + 
  geom_smooth(method = "lm", formula = y ~ x, colour = "violetred3") + 
  see::theme_lucid() +
  scale_x_continuous("predicted reaction time (ms)") +
  scale_y_continuous("empirical mean reaction time (ms)")

# Exporting some data in case we need to sanity check
d %>% filter(exp_id %in% exps2predict) %>%
  group_by(exp_id, p_id, d_feature, N_T) %>%
  summarise(mean_rt = mean(rt), .groups = "drop") %>%
  group_by(exp_id,  d_feature, N_T) %>%
  summarise(mean_rt = mean(mean_rt), .groups = "drop") %>%
  left_join(rt_pred, by = c("exp_id", "d_feature", "N_T")) -> d_out
```

<TODO> show RT predictions for the other two methods?

# Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use a lognormal distribution for modelling reaction times, This allows us to avoid ever predicing impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milli-seconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  
## Measuring $D$ from Empirical Data

We'll make a few minor changes to the data:
  - Switch from ms to seconds
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
```{r}
d %>% mutate(
  rt = rt/1000,
  exp_id = parse_number(exp_id)) -> d
```

### Prior Predictions

We can take the prior model, and then use it to compute our prior predictions!

```{r glmm-prior-sample, cache=TRUE}
prior_model_nrl <- fit_glmm_to_an_exp("1", d, ppc = "only", "normal")
prior_model_log <- fit_glmm_to_an_exp("1", d, ppc = "only", "lognormal")
prior_model_sft <- fit_glmm_to_an_exp("1", d, ppc = "only", "shifted")

```

```{r plt_prior, fig.height=8, fig.cap="Sample Prior predictions for reaction time and log(N+1)."}
plt_nrl <- plot_model_fits_ex(d, 1, prior_model_nrl, 1)
plt_log <- plot_model_fits_ex(d, 1, prior_model_log, 1)
plt_sft <- plot_model_fits_ex(d, 1, prior_model_sft, 1)

plt_nrl / plt_log / plt_sft

```

### Fit Model and Posterior Predictions For Experiment 1

```{r loo-fit-glm-to-buetti2019-data, cache=TRUE}
#m_exp1_nrl <- fit_glmm_to_an_exp(1, d, ppc = "no", fam = "normal")
#saveRDS(m_exp1_nrl, "exp_1_nrl.models")
#rm(m_exp1_nrll)


#m_exp1_log <- fit_glmm_to_an_exp(1, d, ppc = "no", fam = "lognormal")
#m_exp1_sft <- fit_glmm_to_an_exp(1, d, ppc = "no", fam = "shifted")


# 
# my_models_idt <- map("2a", fit_glmm_to_an_exp, d, "identity")
# saveRDS(my_models_idt, "my_idt.models")
# rm(my_models_idt)
# 
# my_models_inv <- map("2a", fit_glmm_to_an_exp, d, "inverse")
# saveRDS(my_models_inv, "my_inv.models")
# rm(my_models_inv)

#my_models_sft <- map("2a", fit_glmm_to_an_exp, d, "shifted")
#saveRDS(my_models_sft, "my_sft.models")
#rm(my_models_sft)

#my_models_inv <- map("2a", fit_glmm_to_an_exp, d, FALSE, "Gamma")

#my_models_nrl <- readRDS("my_nrl.models")[[1]]
#my_models_idt <- readRDS("my_idt.models")[[1]]
#my_models_sft <- readRDS("my_sft.models")[[1]]

#my_models_nrl <- add_criterion(my_models_nrl, c("loo", "waic"))
#my_models_idt <- add_criterion(my_models_idt, c("loo", "waic"))
#my_models_sft <- add_criterion(my_models_sft, c("loo", "waic"))

#model_weights(my_models_idt, my_models_nrl, my_models_sft)
```






<!-- ### Fit Model and Posterior Predictions -->

<!-- ```{r loo-fit-glm-to-buetti2019-data, cache=TRUE} -->
<!-- # my_models_nrl <- map("2a", fit_glmm_to_an_exp, d, "identity", "normal") -->
<!-- # saveRDS(my_models_nrl, "my_nrl.models") -->
<!-- # rm(my_models_nrl) -->
<!-- #  -->
<!-- # my_models_idt <- map("2a", fit_glmm_to_an_exp, d, "identity") -->
<!-- # saveRDS(my_models_idt, "my_idt.models") -->
<!-- # rm(my_models_idt) -->
<!-- #  -->
<!-- # my_models_inv <- map("2a", fit_glmm_to_an_exp, d, "inverse") -->
<!-- # saveRDS(my_models_inv, "my_inv.models") -->
<!-- # rm(my_models_inv) -->

<!-- my_models_sft <- map("2a", fit_glmm_to_an_exp, d, "shifted") -->
<!-- saveRDS(my_models_sft, "my_sft.models") -->
<!-- rm(my_models_sft) -->

<!-- #my_models_inv <- map("2a", fit_glmm_to_an_exp, d, FALSE, "Gamma") -->

<!-- my_models_nrl <- readRDS("my_nrl.models")[[1]] -->
<!-- my_models_idt <- readRDS("my_idt.models")[[1]] -->
<!-- my_models_sft <- readRDS("my_sft.models")[[1]] -->

<!-- my_models_nrl <- add_criterion(my_models_nrl, c("loo", "waic")) -->
<!-- my_models_idt <- add_criterion(my_models_idt, c("loo", "waic")) -->
<!-- my_models_sft <- add_criterion(my_models_sft, c("loo", "waic")) -->

<!-- model_weights(my_models_idt, my_models_nrl, my_models_sft) -->
<!-- ``` -->

<!-- ```{r} -->

<!-- d2 <- filter(d, exp_id == "2a", d_feature != "no distractors")  -->
<!-- d2 <- mutate(d2, d_feature = fct_drop(d_feature)) -->
<!-- d2 %>% mutate(d_feature = as_factor(str_replace_all(d_feature, " ", ""))) -> d2 -->


<!-- samples_nrl <- posterior_samples(my_models_nrl, c("^b","sigma"), subset = 1:10) -->
<!-- samples_idt <- posterior_samples(my_models_idt, c("^b","sigma"), subset = 1:10) -->

<!-- d_nrl <- tibble() -->
<!-- for (n in unique(d$N_T)) { -->

<!--   d_nrl <- bind_rows(d_nrl,  -->
<!--                   map(levels(d2$d_feature), compute_dist, "normal", N_T = n)) -->


<!-- } -->

<!-- d_nrl %>% mutate(d_feature = as_factor(d_feature)) %>% filter(N_T != 0) -> d_nrl -->

<!-- ggplot() +  -->
<!--   geom_density(data = d2, aes(rt, fill = d_feature), alpha = 0.4, position = "identity") +  -->
<!--   geom_path(data = d_nrl, aes(rt, p, group = iter), colour = "purple", alpha = 0.3) + -->
<!--   facet_grid(N_T~d_feature) + coord_cartesian(xlim = c(0, 2)) + ggtitle("normal") -> p1 -->

<!-- d_lnrl <- tibble() -->
<!-- for (n in unique(d$N_T)) { -->

<!--   d_lnrl <- bind_rows(d_lnrl,  -->
<!--                      map(levels(d2$d_feature), compute_dist, "log-normal", N_T = n)) -->


<!-- } -->

<!-- d_lnrl %>% mutate(d_feature = as_factor(d_feature)) %>% filter(N_T != 0) -> d_lnrl -->

<!-- ggplot() +  -->
<!--   geom_density(data = d2, aes(rt, fill = d_feature), alpha = 0.4, position = "identity") +  -->
<!--   geom_path(data = d_lnrl, aes(rt, p, group = iter), colour = "cyan", alpha = 0.3) + -->
<!--   facet_grid(N_T~d_feature) + coord_cartesian(xlim = c(0, 2)) + ggtitle("log normal") -> p2 -->

<!-- p1+p2 -->

<!-- ``` -->


<!-- ```{r fit-glm-to-buetti2019-data, cache=TRUE} -->

<!-- #my_models_idt <- map(unique(d$exp_id), fit_glmm_to_an_exp, d, "identity") -->
<!-- #my_models_inv <- map(unique(d$exp_id), fit_glmm_to_an_exp, d, "inverse") -->


<!-- #saveRDS(my_models_idt, "my.models_idt") -->
<!-- #saveRDS(my_models_inv, "my.models_inv") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #my_models <- readRDS("my.models") -->
<!-- ``` -->

<!-- ```{r plot-glm-to-buetti2019-data, fig.cap="The multi-level fits for Experiment 2a (Buetti, 2019)."} -->
<!-- #plot_model_fits_ex(d, "2a", my_models[[3]], 1:5) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #De <- map_df( -->
<!-- #  1:length(my_models_idt),  -->
<!-- #  extract_fixed_slopes_from_model,  -->
<!-- #  my_models_idt, df = d) -->

<!-- #ggplot(De, aes(x = D, fill = d_feature)) +  -->
<!-- #  geom_density(alpha = 0.333) + -->
<!-- #  facet_wrap(~ exp_id, ncol = 5) +  -->
<!-- #  theme_bw() -->

<!-- #ggsave("../plots/buetti2019_bayesian_fits.pdf", width = 8, height = 3) -->
<!-- ``` -->

<!-- ## Estimating $D$ for compound feature distractors -->

<!-- ```{r} -->

<!-- #Dp_samples <- map_df(exps_to_predict, get_Dp_samples, d) -->

<!-- # add in average D (of collinear and orthogonal) -->

<!-- #Dp_samples %>% pivot_wider(names_from = method, values_from = Dp) %>% -->
<!-- #  group_by(iter, exp_id, d_feature) %>% -->
<!-- #  mutate(mean_method = mean(c(orthog_contrast, collinear))) %>%  -->
<!-- #  pivot_longer(c(best_feature, orthog_contrast, collinear, mean_method), names_to = "method", values_to = "Dp") -> Dp_samples -->


<!-- # Dp_samples %>%  -->
<!-- #   group_by(exp_id, d_feature, method) %>% -->
<!-- #   mean_hdci(Dp, De) %>% -->
<!-- #  ggplot(aes(x = Dp, y = De)) +  -->
<!-- #  geom_abline(linetype = 2) +  -->
<!-- #  geom_point() + -->
<!-- #  facet_wrap(~method, nrow = 1) + theme_bw() + -->
<!-- #  geom_linerange(aes(ymin = De.lower, ymax = De.upper), alpha = 0.5) +  -->
<!-- #  geom_linerange(aes(xmin = Dp.lower, xmax = Dp.lower), alpha = 0.5) +  -->
<!-- #  geom_smooth(method = lm, colour = "pink") -->

<!-- #ggsave("recreate_log_normal_fig_4.pdf", width = 8, height = 2.5) -->

<!-- ``` -->

<!-- ## Which slope is closer to 1? -->

<!-- ```{r} -->
<!-- #slopes_err <- function(ii, df)  { -->

<!-- #  d_itr = filter(df, iter == ii) -->

<!-- #  beta = summary(lm(data = d_itr, De ~ (Dp):(0 + method)))$coefficients[, 1] -->
<!-- #  beta_err = abs(1 - beta) -->

<!-- #  return(beta_err) -->
<!-- #} -->


<!-- #beta_err <- map_df(unique(Dp_samples$iter), slopes_err, Dp_samples)  -->
<!-- #names(beta_err) <- str_remove(names(beta_err), 'Dp:method') -->

<!-- # beta_err %>% pivot_longer(1:4, names_to = "method", values_to = "abs_res") %>% -->
<!-- #   ggplot(aes(x = abs_res, fill = method)) + geom_density(alpha = 0.33) -->

<!-- # beta_err %>% select(-best_feature) %>% -->
<!-- #   mutate(difference = orthog_contrast - collinear) %>% -->
<!-- #   ggplot(aes(x = difference)) + geom_density() -->

<!-- #  beta_err %>% select(-best_feature) %>% -->
<!-- #   mutate(difference = mean_method - collinear) -> x -->

<!-- #  mean(x$difference > 0) -->

<!-- ``` -->

<!-- ## Predicting Reaction Times -->

<!-- ```{r, fig.width = 10, fig.height = 10, cache=TRUE} -->

<!-- # Dp_samples %>%  -->
<!-- #   group_by(exp_id, d_feature, method) %>% -->
<!-- #  summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop")-> Dp_summary -->

<!-- #meth <- "mean_method" -->

<!-- #d_prt <- map_df(exps_to_predict, predict_rt_b, meth, Dp_summary, d) -->
<!-- ``` -->


<!-- ```{r} -->

<!-- #d_rt <- d %>% filter(N_T > 0) %>% -->
<!-- #  group_by(p_id, exp_id, d_feature, N_T) %>% summarise( -->
<!-- #    mean_log = MASS::fitdistr(rt, densfun = "log-normal")$estimate["meanlog"], -->
<!-- #    mean_rt = mean(rt)) %>% -->
<!-- #   group_by(exp_id, d_feature, N_T) %>% summarise(rt = exp(median(mean_log))) %>% -->
<!-- # right_join(d_prt, by = c("exp_id", "d_feature", "N_T")) -->

<!-- #ggplot(data = d_rt, aes(x = rt, y = .value)) +  -->
<!-- #  geom_abline(linetype = 2) + -->
<!-- #  geom_point() + geom_errorbar(aes(ymin = .lower, ymax = .upper))+  -->
<!-- #  theme_bw() -->



<!-- #print(mean(abs(d_rt$rt - d_rt$.value))) -->

<!-- ``` -->
<!-- # Power Analyis for Planned Studies -->
