---
title: "4 Planned Explorations"
author: "Alasdair D.F. Clarke and Anna E. Hughes"
date: "2023-03-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.height = 3,
  fig.align = "center")
```

# Introduction

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
library(ggpmisc)
library(ggridges)
library(corrr)
```

```{r}
# set ggplot2 theme
theme_set(ggthemes::theme_tufte())
colourPalette <- c("#e78429", "#ed968c", "#7c4b73","#aadce0", "#72bcd5", "528fad")

# use parallel cores for mcmc chains!
options(mc.cores = 4)

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

# Individual Differences in D

First, we will look to see the extent to which $D$ varies from one person to the next. We will also ask whether these variations are correlated, both for single and for double feature search. 


```{r cache=TRUE, warning = FALSE}
## Import and Remove Outliers 

source("1_pre_process_data.R")

m1 <- readRDS("exp1.model")
m2 <- readRDS("exp2_random.model")

# Calculate slopes, fixed=FALSE means we will return samples per-observer, rather
# than simply the fixed effects. 
samples1 <- get_slopes(m1, fixed = F)
samples2 <- get_slopes(m2, fixed = F) 
```

## Correlations for single feature search

```{r create_D_obs_plot, cache=TRUE}
ggplot(samples1, aes(x=D, y= as_factor(feature), 
                     group = interaction(observer, feature), fill = feature)) +
  geom_density_ridges(alpha = 0.5) +
  scale_fill_manual(values = colourPalette) + 
  scale_x_continuous(expression(D[c] ~ and ~ D[s])) + 
  scale_y_discrete("feature") + 
  theme(legend.position = "none") -> plt_D_obs
```

Define a little function for computing correlation for a sample from our posterior:

```{r}
compute_corr <- function(drw, df) {
  df %>% filter(.draw==drw) %>%
    select(-.draw) %>%
    correlate(quiet = TRUE) %>%
    stretch() -> dout
  
  return(dout)
}
```

Apply this function to all the samples in our posterior: 

```{r compute_single_feature_corr, cache=TRUE}
samples1 %>% 
  pivot_wider(names_from = "feature", values_from = "D") %>%
  select(-observer) -> dat_for_corr

dcorr <- map_df(unique(dat_for_corr$.draw), compute_corr, dat_for_corr) %>%
  mutate(x = as_factor(x), 
         x = fct_relevel(x, "pink", "purple", "orange"), 
         y = as_factor(y),
         y = fct_relevel(y, "pink", "purple", "orange"))
```

```{r create_single_feat_plot, cache=TRUE}
dcorr %>% group_by(x, y) %>%
  median_hdci(r, .width = 0.97) %>%
  mutate(fill = if_else(.lower>0, "nonezero", "zero")) %>%
  select(x, y, fill) -> dfill


ggplot(left_join(dcorr, dfill, by = c("x", "y")), aes(x, r)) +
  stat_slabinterval(alpha = 0.5, aes(fill = fill), 
                    point_interval = "median_hdci",
                    .width = c(0.53, 0.97), fatten_point = 0) + 
  geom_hline(yintercept = 0, linetype = 2) + 
  facet_wrap(~y) +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1),
        legend.position = "none",
        axis.title.x = element_blank()) +
  scale_y_continuous("Pearson's correlation coefficent", 
                     limits = c(-0.6, 1), expand = c(0, 0), breaks = seq(-0.5, 1, 0.5)) +
  scale_fill_manual(values = c("darkgreen", "black")) -> plt_corr
```

```{r plot_single_feature_corr, warning = FALSE, message = FALSE, echo = FALSE}
plt_D_obs + plt_corr

ggsave("../../plots/single_feature_correlations.pdf", height = 3, width = 8)

rm(plt_D_obs, plt_corr)
```

## Correlations for double feature search 

```{r compute_double_feature_corr, cache=TRUE}
######### Now do double feature search
samples2 %>% 
  pivot_wider(names_from = "feature", values_from = "D") %>%
  select(-observer) -> dat_for_corr

dcorr <- map_df(unique(dat_for_corr$.draw), compute_corr, dat_for_corr) %>%
  mutate(x = as_factor(x), 
         y = as_factor(y))
```

```{r plot_cor_double_feature, fig.height=6, warning = FALSE, echo = FALSE}
ggplot(dcorr, aes(x, r)) +
  stat_slabinterval(.width = c(0.53, 0.97)) + 
  geom_hline(yintercept = 0, linetype = 2) + 
  facet_wrap(~y) +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))

rm(dcorr)
```

## Predicting $D$ per person

In the main manuscript, we combine the single feature search slopes to predict the double feature conditions across all participants. Here, we show the predictions for each participant individually.

```{r calc_D, cache=TRUE}
#########
# Look at how well we can predict Dcs per person
calc_D <- function(feature1, feature2, observer) {
  
  obs <- observer
  D1 <- filter(samples1, feature == feature1, observer == obs)$D
  D2 <- filter(samples1, feature == feature2, observer == obs)$D
  
  # now calculate D_overall using the three proposed methods
  D_collinear = 1/((1/D1) + (1/D2))
  D_best_feature = pmin(D1, D2)
  D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))
  
  return(tibble(.draw = 1:length(unique(samples1$.draw)),
                observer = obs,
                feature = paste(feature1, feature2, sep = "_"),
                feature1 = feature1, feature2 = feature2,
                collinear = D_collinear,
                `best feature` = D_best_feature,
               `orthogonal contrast` = D_orth_contrast,
               ))
}
```

```{r running_calcD, cache=TRUE}
things_to_calc <- samples2 %>% 
  select(-.draw, -D) %>%
  distinct() %>% 
  separate(feature, c("feature1", "feature2")) %>%
  select(feature1, feature2, observer)

slopes <- pmap_df(things_to_calc, calc_D) %>% 
  full_join(samples2, by = c("observer", ".draw", "feature")) %>%
  pivot_longer(c(collinear, `best feature`, `orthogonal contrast`), names_to = "method", values_to = "Dp") %>% 
  group_by(observer, method, feature ) %>%
  summarise(De = median(D), 
            Dp = median(Dp), .groups = "drop")
```

```{r plot_Dp, fig.height = 15, fig.width = 10, message = FALSE}
ggplot(slopes, aes(Dp, De, colour = method)) + geom_point() +
  geom_smooth(method = lm, alpha = 0.25) +
  geom_abline(linetype = 2) + 
  facet_wrap(~observer, nrow = 8)
```

```{r comp_corr, cache=TRUE}
comp_corr <- function(obs, meth) {
  df <- filter(slopes, observer == obs, method == meth)
  r <- cor(df$De, df$Dp)
  return(r)
}

r_col <- map_dbl(1:40, comp_corr, "collinear")
r_bfe <- map_dbl(1:40, comp_corr, "best feature")
r_oth <- map_dbl(1:40, comp_corr, "orthogonal contrast")
```

Below, we can see that across all participants, orthogonal contrast generally has the highest correlation coefficient value, although there are several participants who are very poorly predicted by the orthogonal contrast method (unlike the collinear and the best feature methods).

TO DO: comp_corr with absolue error (rather than r2 value).

```{r plot_Dmeth_corr_hist, message = FALSE, warning = FALSE}
tibble(method = rep(c("collinear", "best feature", "orthogonal contrast"), 
                    each=40),
                r = c(r_col, r_bfe, r_oth)) %>%
  ggplot(aes(r, fill = method)) + geom_histogram(alpha = 0.5, position=position_identity())

```


```{r, include = FALSE}
rm(list = ls(all.names = TRUE))
```


# Ring Things

 First, read in data again:
 
```{r}
source("1_pre_process_data.R")
```
 

## Model comparison Here

```{r ring_mod_comp}

### first compare ring model to non-ring
m1 <- readRDS("exp1_ring.model")
m0 <- readRDS("exp1.model")

# read in csv and kable

rm(m0)

```

First let us check if ring has an effect and interacts with number of distracter and their feature

```{r plot_ring_model, cache=TRUE}

m1 %>% gather_draws(`b_.*`, regex=T) %>%
  select(-.chain, -.iteration) %>% 
  filter(!str_detect(.variable, "ndt")) %>%
  mutate(.variable = str_remove(.variable, "b_"),
         lin_mod_comp = if_else(str_detect(.variable, ":"), "slope", "intercept"),
         ring = as_factor(parse_number(.variable))) -> post

post %>% filter(lin_mod_comp == "slope") %>%
  mutate(feature = str_extract(.variable, "orange|pink|purple|diamond|circle|triangle")) %>%
  ungroup() %>%
  select(-.variable, -lin_mod_comp) -> slopes
  
slopes %>% ggplot(aes(.value, fill = ring)) + geom_density(alpha = 0.5) +
  facet_wrap(~feature) +
  ggthemes::scale_fill_ptol()

d1 %>% modelr::data_grid(feature, ring, lnd = seq(0, 3.5, 0.1)) %>%
  add_epred_draws(m1, ndraws = 100, re_formula = NA) -> pred

ggplot(pred, aes(x = lnd, y = .epred, colour = ring, group = .draw)) +
  geom_path(alpha = 0.1) + 
  facet_wrap(~feature) +
  ggthemes::scale_color_ptol()

ggsave("../../plots/ring_single_feature.pdf", width = 8, height = 4)

```

## Predicting D

```{r cache=TRUE}
# now read in m2 so that we can compute Dp
m2 <- readRDS("exp2_ring.model")

# get slopes!
samples1 <- get_slopes(m1, rings = TRUE)
samples2 <- get_slopes(m2, num_features = 2, rings = TRUE)  
```

```{r}
calc_D <- function(ring, feature1, feature2) {
  
  rn = ring
  D1 <- filter(samples1, ring == rn, feature == feature1)$D
  D2 <- filter(samples1, ring == rn, feature == feature2)$D
  
  # now calculate D_overall using the three proposed methods
  D_collinear = 1/((1/D1) + (1/D2))
  D_best_feature = pmin(D1, D2)
  D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))
  
  return(tibble(.draw = 1:length(unique(samples1$.draw)),
                ring = ring,
               # feature = paste(feature1, feature2, sep = "_"),
                feature1 = feature1, 
               feature2 = feature2,
                collinear = D_collinear,
                `best feature` = D_best_feature,
                `orthogonal contrast` = D_orth_contrast))
}

```

```{r calc_D_run, cache=TRUE}

things_to_calc <- samples2 %>% select( -D, -.draw) %>% 
   distinct()

slopes <- pmap_df(things_to_calc, calc_D) %>% 
  full_join(samples2, 
            by = c(".draw", "feature1", "feature2", "ring")) %>% 
  pivot_longer(c(collinear, `best feature`, `orthogonal contrast`), names_to = "method", values_to = "Dp") %>% 
  pivot_longer(c(D, Dp), names_to = "type", values_to = "D") %>% 
  group_by(feature1, feature2, ring,  method, type) 

slopes %>% 
  median_hdci(D) %>%
  unite(D, D, .lower, .upper) %>% 
  select(-.width, -.point, -.interval) %>% 
  pivot_wider(names_from = "type", values_from = "D") %>% 
  separate(D, into = c("De", "De_min", "De_max"), sep = "_", convert = TRUE) %>% 
  separate(Dp, into = c("Dp", "Dp_min", "Dp_max"), sep = "_", convert=  TRUE) %>%
  filter(is.finite(ring)) %>% 
  ggplot(aes(x = Dp, xmin = Dp_min, xmax = Dp_max, y = De, ymin = De_min, ymax = De_max, colour = as_factor(ring))) + 
  geom_point() + 
  geom_errorbar(alpha = 0.5) + 
  geom_errorbarh(alpha = 0.5) + 
  geom_abline(linetype = 2) + 
  geom_smooth(method = "lm", fullrange  = T) +
  # stat_poly_eq(formula = y ~ x, 
  #              aes(label = paste(..eq.label.., ..rr.label.., sep = "*plain(\",\")~")), 
  #              parse = TRUE, size = 2.8, label.y = 0.9, coef.digits = 3, rr.digits = 4, colour="blue") + 
  facet_wrap(~method, scales = "free") +
  ggthemes::scale_color_ptol("target ring")

ggsave("../../plots/target_ring_D_pred.pdf",  width = 8, height = 3)

```


```{r}

# compute prediction error

slopes  %>% 
  ungroup() %>% 
  pivot_wider(names_from = "type", values_from = "D") %>% 
  mutate(abs_err = abs(D-Dp)) %>% 
  group_by(ring, feature1, feature2, method) %>% 
  summarise(mean_abs_err = mean(abs_err), .groups = "drop") %>% 
  pivot_wider(names_from = "method", values_from = "mean_abs_err") %>% 
  ungroup() -> slopes_err 


add_row(slopes_err, ring = 0, feature1 = "sum", feature2 = "over all", 
        `best feature` = sum(slopes_err[4]), 
        collinear = sum(slopes_err[5]), 
        `orthogonal contrast` = sum(slopes_err[6])) %>% 
  knitr::kable() 

slopes  %>% 
  ungroup() %>% 
  pivot_wider(names_from = "type", values_from = "D") %>%
  mutate(ring = as_factor(ring)) -> slopes

summary(lm(D ~ 0 + ring + ring:Dp, 
           data = filter(slopes, method == "best feature")))

summary(lm(D ~ 0 + ring + ring:Dp, 
           data = filter(slopes, method == "collinear")))

summary(lm(D ~ 0 + ring + ring:Dp, 
           data = filter(slopes, method == "orthogonal contrast")))

```