knitr::opts_chunk$set(
echo = TRUE,
fig.height = 3,
fig.align = "center")
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
# set ggplot2 theme
theme_set(see::theme_abyss())
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# reduce the number of decimal places
options(digits = 3)
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# set seed to make sure everything is reproducible
set.seed(100320021)
source("../scripts/import_and_tidy.R")
summary(d)
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4
# remove outlier RTs
d <- our_changes_to_data(d)
d0 <-  filter(d, N_T == 0)
ggplot(d0, aes(x = rt, fill = exp_id)) + geom_density(alpha = 0.2) +
xlim(0, 2)
my_f <- bf(rt ~ 0 + exp_id + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
my_prior <- c(
prior_string("normal(0, 0.2)", class = "b"),
prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
prior_string("cauchy(0, 0.4)", class = "sigma"),
prior_string("cauchy(0, 0.05)", class = "sd"),
prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))
a_m <- brm(my_f,
data = d0,
prior = my_prior,
inits =my_inits,
chains = 4,
iter = 5000,
family = shifted_lognormal())
readRDS("models/intercepts.models")
saveRDS("models/intercepts.models")
saveRDS(a_m, "models/intercepts.models")
summary(a_m)
knitr::opts_chunk$set(
echo = TRUE,
fig.height = 3,
fig.align = "center")
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
# set ggplot2 theme
theme_set(see::theme_abyss())
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# reduce the number of decimal places
options(digits = 3)
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# set seed to make sure everything is reproducible
set.seed(100320021)
source("../scripts/import_and_tidy.R")
summary(d)
d <- our_changes_to_data(d)
d
knitr::opts_chunk$set(
echo = TRUE,
fig.height = 3,
fig.align = "center")
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
# set ggplot2 theme
theme_set(see::theme_abyss())
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# reduce the number of decimal places
options(digits = 3)
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# set seed to make sure everything is reproducible
set.seed(100320021)
source("../scripts/import_and_tidy.R")
summary(d)
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4
# remove outlier RTs
d <- our_changes_to_data(d)
prior_model_nrl <- readRDS("models/prior_nrl.models")
prior_model_log <- readRDS("models/prior_log.models")
prior_model_sft <- readRDS("models/prior_sft.models")
plt_nrl <- plot_model_fits_rt(1, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "blue")
plot_model_fits_rt <- function(e_id, m, plot_type = 'predicted', y_limits = c(0, 1.5), n_row = 1, feature2plot = 'all', dot_col = "yellow1") {
# plot search slopes for experiment e_id
# take the experiment we want, and remove the N_T == 0 case.
if (feature2plot == "all") {
d %>%
filter(
exp_n == e_id) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
ungroup() -> d_plt
} else {
d %>%
filter(
exp_n== e_id, d_feature == feature2plot) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) -> d_plt
}
if (plot_type == "predicted") {
# include all group-level effects.
# Let's simulate 100 new people!
d_plt %>%
modelr::data_grid(N_T = seq(0,36,4), d_feature, p_id = 1:100)  %>%
add_predicted_draws(m, re_formula = NULL, allow_new_levels = TRUE, n = 100) %>%
ungroup() %>%
select(-p_id) %>%
group_by(d_feature, N_T) -> d_hdci
} else {
# no group-level effects are included, so we are plotting
# for the average participant
d_plt %>%
modelr::data_grid(N_T = seq(0,36,4), d_feature) %>%
add_fitted_draws(m, re_formula = NA, scale = "response", n = 500) -> d_hdci
# we will plot these against the mean mean rt
d_plt %>% group_by(N_T, d_feature, p_id) %>%
summarise(mean_rt = mean(rt), .groups = "drop") %>%
group_by(N_T, d_feature) %>%
summarise(mean_rt = mean(mean_rt), .groups = "drop") -> d_plt
}
# calc 53% and 97% intervals for the model
d_hdci %>% mean_hdci(.width = c(0.53, 0.97)) -> d_hdci
plt <- plot_ribbon_quantiles(d_hdci, d_plt, y_limits, n_row, plot_type, dot_col)
return(plt)
}
plt_nrl <- plot_model_fits_rt(1, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "blue")
knitr::opts_chunk$set(
echo = TRUE,
fig.height = 3,
fig.align = "center")
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
# set ggplot2 theme
theme_set(see::theme_abyss())
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# reduce the number of decimal places
options(digits = 3)
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# set seed to make sure everything is reproducible
set.seed(100320021)
source("../scripts/import_and_tidy.R")
summary(d)
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4
# remove outlier RTs
d <- our_changes_to_data(d)
prior_model_nrl <- readRDS("models/prior_nrl.models")
prior_model_log <- readRDS("models/prior_log.models")
prior_model_sft <- readRDS("models/prior_sft.models")
plt_nrl <- plot_model_fits_rt(1, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "blue")
plt_log <- plot_model_fits_rt(1, prior_model_log, y_limits = c(0, 10), feature2plot = "blue")
plt_sft <- plot_model_fits_rt(1, prior_model_sft, y_limits = c(0, 10), feature2plot = "blue")
#### Set up and data import ####
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(magrittr)
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# functions used for the analysis implementation
source("../scripts/reimplementation.R")
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# import and tidy data
source("../scripts/import_and_tidy.R")
# switch from ms to seconds
# Recode experiment as 1, 2, 3 and 4
d <- our_changes_to_data(d)
mdl_inputs_sft <- set_up_model("1a", "shifted_lognormal")
prior_model_sft <- run_model(mdl_inputs_sft, ppc = "only")
mdl_inputs_sft <- set_up_model(training_models, "shifted_lognormal")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
#### Fit model for Expt 1&3 ####
training_models <- c("1a", "1b", "3a", "3b")
mdl_inputs_sft <- set_up_model(training_models, "shifted_lognormal")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
set_up_model <- function(experiment, fam = "lognormal") {
# this function get's everything ready for running our model
# mainly, this involves defining priors.
# check fam input is ok!
if (!(fam %in% c("normal", "lognormal", "shifted_lognormal"))) {
print("error")
stop()
}
# subset data to take just th experiment that we're inserted in
d %>%
filter(exp_id %in% experiment) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
select(p_id, exp_id, N_T, d_feature, rt) -> df
# define model formula:
if (fam == "shifted_lognormal") {
my_f <- bf(rt ~ 0 + exp_id + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 0 + exp_id + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
} else {
my_f <- rt ~  0 + exp_id + d_feature:log(N_T+1) + (1|p_id)
my_inits <- "random"
}
#list of variables/coefs that we want to define priors for:
#intercepts <- paste("d_feature", levels(df$d_feature), sep = "")
#intercepts <- gsub("[[:space:]]", "", intercepts)
#slopes <- paste("d_feature", levels(df$d_feature), ":logN_TP1", sep = "")
#slopes <- gsub("[[:space:]]", "", slopes)
intercepts = paste("exp_id", experiment, sep = "")
# now define priors, based on our choice of distribution:
if ( fam == "lognormal") {
my_prior <- c(
prior_string("normal(-0.5, 0.3)",  class = "b", coef = intercepts),
prior_string("normal(0.1, 0.3)", class = "b"),
prior_string("cauchy(0, 0.1)", class = "sigma"))
} else if(fam == "shifted_lognormal") {
my_prior <- c(
prior_string("normal(-0.5, 0.3)",  class = "b", coef = intercepts),
prior_string("normal(0, 0.2)", class = "b"),
prior_string("normal(-1, 0.5)", class = "b", dpar = "ndt" ),
prior_string("cauchy(0, 0.4)", class = "sigma"),
prior_string("cauchy(0, 0.05)", class = "sd"),
prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))
} else {
# use a normal distribution
my_prior <- c(
prior_string("normal(0, 0.25)", class = "b"),
prior_string("normal(0.5, 0.2)", class = "b", coef = intercepts),
prior_string("normal(0, 0.25)", class = "sigma"),
prior_string("normal(0, 0.25)", class = "sd"))
}
return(list(my_formula = my_f, my_inits = my_inits, my_prior = my_prior, df = df, my_dist = fam))
}
mdl_inputs_sft <- set_up_model(training_models, "shifted_lognormal")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
set_up_model <- function(experiment, fam = "lognormal") {
# this function get's everything ready for running our model
# mainly, this involves defining priors.
# check fam input is ok!
if (!(fam %in% c("normal", "lognormal", "shifted_lognormal"))) {
print("error")
stop()
}
# subset data to take just th experiment that we're inserted in
d %>%
filter(exp_id %in% experiment) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
select(p_id, exp_id, N_T, d_feature, rt) -> df
# define model formula:
if (fam == "shifted_lognormal") {
my_f <- bf(rt ~ 0 + exp_id + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
} else {
my_f <- rt ~  0 + exp_id + d_feature:log(N_T+1) + (1|p_id)
my_inits <- "random"
}
#list of variables/coefs that we want to define priors for:
#intercepts <- paste("d_feature", levels(df$d_feature), sep = "")
#intercepts <- gsub("[[:space:]]", "", intercepts)
#slopes <- paste("d_feature", levels(df$d_feature), ":logN_TP1", sep = "")
#slopes <- gsub("[[:space:]]", "", slopes)
intercepts = paste("exp_id", experiment, sep = "")
# now define priors, based on our choice of distribution:
if ( fam == "lognormal") {
my_prior <- c(
prior_string("normal(-0.5, 0.3)",  class = "b", coef = intercepts),
prior_string("normal(0.1, 0.3)", class = "b"),
prior_string("cauchy(0, 0.1)", class = "sigma"))
} else if(fam == "shifted_lognormal") {
my_prior <- c(
prior_string("normal(-0.5, 0.3)",  class = "b", coef = intercepts),
prior_string("normal(0, 0.2)", class = "b"),
prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
prior_string("cauchy(0, 0.4)", class = "sigma"),
prior_string("cauchy(0, 0.05)", class = "sd"),
prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))
} else {
# use a normal distribution
my_prior <- c(
prior_string("normal(0, 0.25)", class = "b"),
prior_string("normal(0.5, 0.2)", class = "b", coef = intercepts),
prior_string("normal(0, 0.25)", class = "sigma"),
prior_string("normal(0, 0.25)", class = "sd"))
}
return(list(my_formula = my_f, my_inits = my_inits, my_prior = my_prior, df = df, my_dist = fam))
}
mdl_inputs_sft <- set_up_model(training_models, "shifted_lognormal")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
saveRDS(m_exp1_sft, "models/exp_1_3_sft.models")
#### Set up and data import ####
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(magrittr)
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# functions used for the analysis implementation
source("../scripts/reimplementation.R")
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# import and tidy data
source("../scripts/import_and_tidy.R")
# switch from ms to seconds
# Recode experiment as 1, 2, 3 and 4
d <- our_changes_to_data(d)
mdl_inputs_sft <- set_up_model(training_models, "shifted_lognormal")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
saveRDS(m_exp1_sft, "models/exp_1_3_sft.models")
#### Fit model for Expt 1&3 ####
training_models <- c("1a", "1b", "3a", "3b")
mdl_inputs_sft <- set_up_model(training_models, "shifted_lognormal")
m_exp1_sft <- run_model(mdl_inputs_sft, ppc = "no")
saveRDS(m_exp1_sft, "models/exp_1_3_sft.models")
summary(m_exp1_sft)
loo_m_exp1_nrl <- loo(m_exp1_nrl, nsamples=4500)
saveRDS(loo_m_exp1_nrl, "models/loo_m_exp13_nrl.rds")
loo_m_exp1_log <- loo(m_exp1_log, nsamples=4500, moment_match = TRUE)
saveRDS(loo_m_exp1_log, "models/loo_m_exp13_log.rds")
loo_m_exp1_sft <- loo(m_exp1_sft, nsamples=4500, moment_match = TRUE)
saveRDS(loo_m_exp1_sft, "models/loo_m_exp13_sft.rds")
loo_m_exp1_sft <- loo(m_exp1_sft, nsamples=4500, moment_match = TRUE)
?loo
