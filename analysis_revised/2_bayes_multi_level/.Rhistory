geom_linerange(aes(x = Dp, ymin = De.lower, ymax = De.upper), color = dot_col) +
# geom_linerange(aes(y = De, xmin = Dp.lower, xmax = Dp.upper), color = dot_col) +
geom_abline(data = Dp_lines, aes(intercept = intercept, slope = slope), colour = "palevioletred1", alpha = 0.1) +
facet_wrap(~method, nrow = 1) +
# geom_ribbon(data = Dp_lines, aes(x = x,  ymin = .lower, ymax=  .upper), alpha = 0.5, fill = "palevioletred1") +
coord_fixed(xlim = c(0, 0.25), ylim = c(0, 0.25)) +
scale_x_continuous(TeX("Predicted value for $D_{c,s}$"), expand = c(0, 0), breaks = c(0, 0.1, 0.2)) +
scale_y_continuous(TeX("empirical value for $D_{c,s}$"), expand = c(0, 0), breaks = c(0, 0.1, 0.2))
}
plot_Dp_lines(Dp_lines)
Dp_samples
Dp_samples %>% group_by(exp_id, d_feature) %>% summarise(De = mean(De), Dp = mean(Dp))
Dp_lines
Dp_lines <- get_Dp_lines(Dp_samples %>% filter(exp_id %in% c("4a", "4b", "4c")))
plot_Dp_lines(Dp_lines)
Dp_lines <- get_Dp_lines(Dp_samples)
knitr::opts_chunk$set(
echo = TRUE,
fig.height = 3,
fig.align = "center")
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
# set ggplot2 theme
theme_set(see::theme_abyss())
# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())
# reduce the number of decimal places
options(digits = 3)
# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
# set seed to make sure everything is reproducible
set.seed(100320021)
source("../scripts/import_and_tidy.R")
summary(d)
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4
# remove outlier RTs
d <- our_changes_to_data(d)
prior_model_nrl <- readRDS("models/prior_nrl.models")
prior_model_log <- readRDS("models/prior_log.models")
prior_model_sft <- readRDS("models/prior_sft.models")
training_models = c("1a", "1b")
plt_nrl <- plot_model_fits_rt(training_models, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "all")
plt_log <- plot_model_fits_rt(training_models, prior_model_log, y_limits = c(0, 10), feature2plot = "all")
plt_sft <- plot_model_fits_rt(training_models, prior_model_sft, y_limits = c(0, 10), feature2plot = "all")
plt_nrl / plt_log / plt_sft
# tidy up, we no longer need to keep hold of these models and plots
rm(
prior_model_nrl,
prior_model_log,
prior_model_sft,
plt_nrl, plt_log, plt_sft)
m_exp1_nrl <- readRDS("models/exp_1_nrl.models")
m_exp1_log <- readRDS("models/exp_1_log.models")
m_exp1_sft <- readRDS("models/exp_1_sft.models")
#m_exp1_sft_nolog <- readRDS("models/exp_1_3_sft_nolog.models")
plt_nrl <- plot_model_fits_rt(training_models, m_exp1_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(training_models, m_exp1_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(training_models, m_exp1_sft, plot_type = "fitted")
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")
plt_nrl / plt_log / plt_sft #/ plt_sft_nolog
rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
plt_nrl <- plot_model_fits_rt(training_models, m_exp1_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(training_models, m_exp1_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(training_models, m_exp1_sft, plot_type = "predicted", y_limits = c(0, 2.5))
# plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))
plt_nrl / plt_log / plt_sft #/ plt_sft_nolog
rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
bs_exp1_nrl <- bridge_sampler(m_exp1_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp1_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp1_sft, silent = TRUE)
#bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)
tibble(model = c("normal", "lognormal", "shifted-lognormal"), #, "linear in $N_T$"
weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft)) %>% # , bs_exp1_sft_nolog
knitr::kable()
#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
summary(m_exp1_sft)
plot(m_exp1_sft, pars = "^b_")
m_exp3_nrl <- readRDS("models/exp_3_nrl.models")
m_exp3_log <- readRDS("models/exp_3_log.models")
m_exp3_sft <- readRDS("models/exp_3_sft.models")
#m_exp1_sft_nolog <- readRDS("models/exp_1_3_sft_nolog.models")
training_models = c("3a", "3b")
plt_nrl <- plot_model_fits_rt(training_models, m_exp3_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(training_models, m_exp3_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(training_models, m_exp3_sft, plot_type = "fitted")
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")
plt_nrl / plt_log / plt_sft #/ plt_sft_nolog
rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
plt_nrl <- plot_model_fits_rt(training_models, m_exp3_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(training_models, m_exp3_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(training_models, m_exp3_sft, plot_type = "predicted", y_limits = c(0, 2.5))
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))
plt_nrl / plt_log / plt_sft# / plt_sft_nolog
rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
bs_exp1_nrl <- bridge_sampler(m_exp3_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp3_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp3_sft, silent = TRUE)
#bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)
tibble(model = c("normal", "lognormal", "shifted-lognormal"), #, "linear in $N_T$"
weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft)) %>% # , bs_exp1_sft_nolog
knitr::kable()
#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
#load previously fitted models
m_exp2_sft <- readRDS("models/exp_2_sft.models")
m_exp4_sft <- readRDS("models/exp_4_sft.models")
slopes1 <- extract_fixed_slopes_from_model(m_exp1_sft)
slopes2 <- extract_fixed_slopes_from_model(m_exp2_sft)
slopes3 <- extract_fixed_slopes_from_model(m_exp3_sft)
slopes4 <- extract_fixed_slopes_from_model(m_exp4_sft)
bind_rows(
slopes1 %>% mutate(exp = "Experiment 1"),
slopes3 %>% mutate(exp = "Experiment 3")) %>%
ggplot(aes(x= D, fill = d_feature)) +
geom_density(alpha = 0.5) +
facet_wrap(~exp, nrow = 2)
Dp_samples <- bind_rows(
map_dfr(c("2a", "2b", "2c"), get_Dp_samples, d, slopes1, slopes2),
map_dfr(c("4a", "4b", "4c"), get_Dp_samples, d, slopes3, slopes4))
# get best possible linear fit of the various methods!
Dp_samples %>%
pivot_wider(
c(exp_id, d_feature, iter, De),
names_from = method, values_from = Dp) -> d_lmer
# find mle best fit
m_lmer <- lme4::lmer(data = d_lmer, De ~ best_feature + orthog_contrast + collinear + (1|iter))
d_lmer %>%
mutate(linear_comb = predict(m_lmer)) %>%
pivot_longer(
c(best_feature, orthog_contrast, collinear, linear_comb),
names_to = "method",
values_to = "Dp") %>%
mutate(method = fct_relevel(method, "linear_comb", after = Inf)) -> Dp_samples
#Dp_samples %>% group_by(exp_id, d_feature) %>% summarise(De = mean(De), Dp = mean(Dp))
rm(d_lmer, m_lmer)
Dp_lines <- get_Dp_lines(Dp_samples)
plot_Dp_lines(Dp_lines)
rm(slopes1, slopes2, slopes3, slopes4)
VarCorr(m_exp1_sft)$p_id$sd
VarCorr(m_exp2_sft)$p_id$sd
VarCorr(m_exp1_sft)$residual$sd
VarCorr(m_exp2_sft)$residual$sd
compute_rt_predictions <- function(meth) {
Dp_samples %>%
filter(method == meth) %>%
group_by(exp_id, d_feature) %>%
summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
mutate(
d_feature = as_factor(d_feature),
method = meth) -> Dp_summary
# now define and run new model!
model_params <- set_up_predict_model("2", "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")
return(m_prt)
}
m_prt_best_feature <- compute_rt_predictions(meth = "best_feature")
compute_rt_predictions <- function(meth) {
Dp_samples %>%
filter(method == meth) %>%
group_by(exp_id, d_feature) %>%
summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
mutate(
d_feature = as_factor(d_feature),
method = meth) -> Dp_summary
# now define and run new model!
model_params <- set_up_predict_model("2a", "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")
return(m_prt)
}
m_prt_best_feature <- compute_rt_predictions(meth = "best_feature")
plot_model_fits_rt(2, m_prt_best_feature, y_limits = c(0.2, 0.8), n_row = 3, plot_type = "fitted")
compute_rt_predictions <- function(meth) {
Dp_samples %>%
filter(method == meth) %>%
group_by(exp_id, d_feature) %>%
summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
mutate(
d_feature = as_factor(d_feature),
method = meth) -> Dp_summary
# now define and run new model!
model_params <- set_up_predict_model(c("2a", "2b", "2c"), "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")
return(m_prt)
}
m_prt_best_feature <- compute_rt_predictions(meth = "best_feature")
compute_rt_predictions <- function(meth) {
Dp_samples %>%
filter(method == meth) %>%
group_by(exp_id, d_feature) %>%
summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
mutate(
d_feature = as_factor(d_feature),
method = meth) -> Dp_summary
# now define and run new model!
model_params <- set_up_predict_model(2, "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")
return(m_prt)
}
m_prt_best_feature <- compute_rt_predictions(meth = "best_feature")
meth = "best_feature"
Dp_samples %>%
filter(method == meth) %>%
group_by(exp_id, d_feature) %>%
summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
mutate(
d_feature = as_factor(d_feature),
method = meth) -> Dp_summary
experiment = 2
fam = "lognormal"
# subset data to take just th experiment that we're inserted in
d %>%
filter(exp_id %in% experiment) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
select(p_id, exp_id, N_T, d_feature, rt) -> df
my_f <- bf(rt ~ 0 + exp_id + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
intercepts = paste("exp_id", experiment, sep = "")
my_prior <- c(
prior_string("normal(-0.5, 0.3)",  class = "b", coef = intercepts),
prior_string("normal(0, 0.2)", class = "b"),
prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
prior_string("cauchy(0, 0.4)", class = "sigma"),
prior_string("cauchy(0, 0.05)", class = "sd"),
prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))
# use a normal distribution
my_prior <- c(
prior_string("normal(0, 0.25)", class = "b"),
prior_string("normal(0.5, 0.2)", class = "b", coef = intercepts),
prior_string("normal(0, 0.25)", class = "sigma"),
prior_string("normal(0, 0.25)", class = "sd"))
list(my_formula = my_f, my_inits = my_inits, my_prior = my_prior, df = df, my_dist = fam)
set_up_predict_model <- function(e_id, fam = "shifted_lognormal", meth, Dp_summary, one_feature_model, two_feature_model) {
# this function get's everything ready for running our model
# this is the prediction version of the set_up_model() function at the top of the script
d %>%
filter(exp_id %in% e_id) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) -> df
# define model formula:
if (fam == "shifted_lognormal") {
my_f <- bf(rt ~ 1 + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
} else {
my_f <- rt ~ 1 + log(N_T+1):d_feature + (1|p_id)
my_inits <- "random"
}
Dp_summary <- filter(Dp_summary,
method == meth, exp_id == e_id)
df %>%
filter(exp_id == e_id) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
filter(d_feature != "no distractors") %>%
mutate(
d_feature = fct_drop(d_feature),
d_feature = as.factor(as.character(d_feature))) -> df
# cheatign a little and using the "correct" intercepts
# (from the double feature model)
intercept_mu <- fixef(two_feature_model)[1,1]
intercept_sd <- fixef(two_feature_model)[1,2]
ndt_int_mu <- fixef(two_feature_model)[2,1]
ndt_int_sd <- fixef(two_feature_model)[2,2]
# simply copy over from experiment 1
sigma_mean <-  VarCorr(one_feature_model)$residual$sd[1]
sigma_sd   <-  VarCorr(one_feature_model)$residual$sd[2]
sd_mean <- VarCorr(one_feature_model)$p_id$sd[1,1]
sd_sd <- VarCorr(one_feature_model)$p_id$sd[1,2]
sd_ndt_mean <- VarCorr(one_feature_model)$p_id$sd[2,1]
sd_ndt_sd <- VarCorr(one_feature_model)$p_id$sd[2,2]
# use our model of D!
slopes <- convert_d_feature_to_coef_name(Dp_summary$d_feature)
slopes_mu <-Dp_summary$mu
slopes_sd <-Dp_summary$sigma
my_prior <-  c(
prior_string(paste("normal(", intercept_mu, ",",  intercept_sd, ")", sep = ""), class = "Intercept"),
prior_string(paste("normal(", slopes_mu, ",",  slopes_sd, ")", sep = ""), class = "b", coef = slopes),
prior(normal(sigma_mean, sigma_sd), class = "sigma"),
prior(normal(sd_mean, sd_sd), class = "sd"),
prior_string(paste("normal(",ndt_int_mu, ", ", ndt_int_sd, ")"), class = "Intercept", dpar = "ndt" ),
prior_string(paste("normal(",sd_ndt_mean,",", sd_ndt_sd,")"), class = "sd", dpar = "ndt")
)
stanvars <- stanvar(sigma_mean, name='sigma_mean') +
stanvar(sigma_sd, name='sigma_sd') +
stanvar(sd_mean, name='sd_mean') +
stanvar(sd_sd, name='sd_sd')
return(list(my_formula = my_f, my_inits = my_inits, my_prior = my_prior, df = df, my_dist = fam, my_stanvar = stanvars))
}
model_params <- set_up_predict_model(2, "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")
my_inputs = model_params
ppc = "only"
if (ppc == "only") {
n_chains = 4
n_itr = 5000
} else {
n_chains = 4
n_itr = 5000
}
my_inputs$df %>%
group_by(p_id, exp_id, d_feature, N_T) %>%
summarise(rt = sample(rt, 1), .groups = "drop") -> my_inputs$df
my_inputs$df
View(my_inputs)
# subset data to take just th experiment that we're inserted in
d %>%
filter(exp_id %in% experiment) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
select(p_id, exp_id, N_T, d_feature, rt) -> df
df
d %>%
filter(exp_id %in% experiment)
d
experiment
set_up_predict_model <- function(e_id, fam = "shifted_lognormal", meth, Dp_summary, one_feature_model, two_feature_model) {
# this function get's everything ready for running our model
# this is the prediction version of the set_up_model() function at the top of the script
d %>%
filter(exp_id %in% e_id) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) -> df
# define model formula:
if (fam == "shifted_lognormal") {
my_f <- bf(rt ~ 1 + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
} else {
my_f <- rt ~ 1 + log(N_T+1):d_feature + (1|p_id)
my_inits <- "random"
}
Dp_summary <- filter(Dp_summary,
method == meth, exp_id == e_id)
df %>%
filter(exp_id == e_id) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
filter(d_feature != "no distractors") %>%
mutate(
d_feature = fct_drop(d_feature),
d_feature = as.factor(as.character(d_feature))) -> df
# cheatign a little and using the "correct" intercepts
# (from the double feature model)
intercept_mu <- fixef(two_feature_model)[1,1]
intercept_sd <- fixef(two_feature_model)[1,2]
ndt_int_mu <- fixef(two_feature_model)[2,1]
ndt_int_sd <- fixef(two_feature_model)[2,2]
# simply copy over from experiment 1
sigma_mean <-  VarCorr(one_feature_model)$residual$sd[1]
sigma_sd   <-  VarCorr(one_feature_model)$residual$sd[2]
sd_mean <- VarCorr(one_feature_model)$p_id$sd[1,1]
sd_sd <- VarCorr(one_feature_model)$p_id$sd[1,2]
sd_ndt_mean <- VarCorr(one_feature_model)$p_id$sd[2,1]
sd_ndt_sd <- VarCorr(one_feature_model)$p_id$sd[2,2]
# use our model of D!
slopes <- convert_d_feature_to_coef_name(Dp_summary$d_feature)
slopes_mu <-Dp_summary$mu
slopes_sd <-Dp_summary$sigma
my_prior <-  c(
prior_string(paste("normal(", intercept_mu, ",",  intercept_sd, ")", sep = ""), class = "Intercept"),
prior_string(paste("normal(", slopes_mu, ",",  slopes_sd, ")", sep = ""), class = "b", coef = slopes),
prior(normal(sigma_mean, sigma_sd), class = "sigma"),
prior(normal(sd_mean, sd_sd), class = "sd"),
prior_string(paste("normal(",ndt_int_mu, ", ", ndt_int_sd, ")"), class = "Intercept", dpar = "ndt" ),
prior_string(paste("normal(",sd_ndt_mean,",", sd_ndt_sd,")"), class = "sd", dpar = "ndt")
)
stanvars <- stanvar(sigma_mean, name='sigma_mean') +
stanvar(sigma_sd, name='sigma_sd') +
stanvar(sd_mean, name='sd_mean') +
stanvar(sd_sd, name='sd_sd')
return(list(my_formula = my_f, my_inits = my_inits, my_prior = my_prior, df = df, my_dist = fam, my_stanvar = stanvars))
}
model_params <- set_up_predict_model(c("2a", "2b", "2c"), "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
e_id = c("2a", "2b", "2c")
d %>%
filter(exp_id %in% e_id)
d %>%
filter(exp_id %in% e_id) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) -> df
df
my_f <- bf(rt ~ 1 + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
Dp_summary <- filter(Dp_summary,
method == meth, exp_id == e_id)
df %>%
filter(exp_id == e_id) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
filter(d_feature != "no distractors") %>%
mutate(
d_feature = fct_drop(d_feature),
d_feature = as.factor(as.character(d_feature))) -> df
df %>%
filter(exp_id %in% e_id) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) %>%
filter(d_feature != "no distractors") %>%
mutate(
d_feature = fct_drop(d_feature),
d_feature = as.factor(as.character(d_feature))) -> df
df %>%
filter(d_feature != "no distractors") %>%
mutate(
d_feature = fct_drop(d_feature),
d_feature = as.factor(as.character(d_feature))) -> df
# cheatign a little and using the "correct" intercepts
# (from the double feature model)
intercept_mu <- fixef(two_feature_model)[1,1]
intercept_sd <- fixef(two_feature_model)[1,2]
ndt_int_mu <- fixef(two_feature_model)[2,1]
set_up_predict_model <- function(e_id, fam = "shifted_lognormal", meth, Dp_summary, one_feature_model, two_feature_model) {
# this function get's everything ready for running our model
# this is the prediction version of the set_up_model() function at the top of the script
d %>%
filter(exp_id %in% e_id) %>%
group_by(exp_id, p_id, d_feature, N_T) %>%
mutate(
d_feature = fct_drop(d_feature),
p_id = fct_drop(p_id)) -> df
# define model formula:
if (fam == "shifted_lognormal") {
my_f <- bf(rt ~ 1 + d_feature:log(N_T+1) + (1|p_id),
ndt ~ 1 + (1|p_id))
my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))
} else {
my_f <- rt ~ 1 + log(N_T+1):d_feature + (1|p_id)
my_inits <- "random"
}
Dp_summary <- filter(Dp_summary,
method == meth, exp_id == e_id)
df %>%
filter(d_feature != "no distractors") %>%
mutate(
d_feature = fct_drop(d_feature),
d_feature = as.factor(as.character(d_feature))) -> df
# cheatign a little and using the "correct" intercepts
# (from the double feature model)
intercept_mu <- fixef(two_feature_model)[1,1]
intercept_sd <- fixef(two_feature_model)[1,2]
ndt_int_mu <- fixef(two_feature_model)[2,1]
ndt_int_sd <- fixef(two_feature_model)[2,2]
# simply copy over from experiment 1
sigma_mean <-  VarCorr(one_feature_model)$residual$sd[1]
sigma_sd   <-  VarCorr(one_feature_model)$residual$sd[2]
sd_mean <- VarCorr(one_feature_model)$p_id$sd[1,1]
sd_sd <- VarCorr(one_feature_model)$p_id$sd[1,2]
sd_ndt_mean <- VarCorr(one_feature_model)$p_id$sd[2,1]
sd_ndt_sd <- VarCorr(one_feature_model)$p_id$sd[2,2]
# use our model of D!
slopes <- convert_d_feature_to_coef_name(Dp_summary$d_feature)
slopes_mu <-Dp_summary$mu
slopes_sd <-Dp_summary$sigma
my_prior <-  c(
prior_string(paste("normal(", intercept_mu, ",",  intercept_sd, ")", sep = ""), class = "Intercept"),
prior_string(paste("normal(", slopes_mu, ",",  slopes_sd, ")", sep = ""), class = "b", coef = slopes),
prior(normal(sigma_mean, sigma_sd), class = "sigma"),
prior(normal(sd_mean, sd_sd), class = "sd"),
prior_string(paste("normal(",ndt_int_mu, ", ", ndt_int_sd, ")"), class = "Intercept", dpar = "ndt" ),
prior_string(paste("normal(",sd_ndt_mean,",", sd_ndt_sd,")"), class = "sd", dpar = "ndt")
)
stanvars <- stanvar(sigma_mean, name='sigma_mean') +
stanvar(sigma_sd, name='sigma_sd') +
stanvar(sd_mean, name='sd_mean') +
stanvar(sd_sd, name='sd_sd')
return(list(my_formula = my_f, my_inits = my_inits, my_prior = my_prior, df = df, my_dist = fam, my_stanvar = stanvars))
}
model_params <- set_up_predict_model(c("2a", "2b", "2c"), "shifted_lognormal", meth, Dp_summary, m_exp1_sft, m_exp2_sft)
m_prt <- run_model(model_params, ppc = "only")
m_prt
99*3
298/600
99/100 * 1/6
99/100 * 1/6 + 1/100*1/2
297/600
(99/100 * 1/6) + (1/100*1/2)
99/600 + 1/200
99/600 + 3/600
0.01*0.5/0.17
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
set.seed(947)
tibble(x = seq(-3, 3, 0.01),  y= dnorm(x)) %>% ggplot(aes(x, y)) + geom_path() + theme_bw() +
scale_x_continuous(breaks = NULL)
tibble(x = seq(5000, 25000, 10),  y= dnorm(x, 15000, 2500)) %>% ggplot(aes(x, y)) + geom_path() + theme_bw() + scale_x_continuous("Average number of students at UK University")
d <- tibble(
university = c("2018/19 Mean", "Essex", "Manchester", "Aberystwyth", "Oxford" ),
students = c(15858, 12050, 26855, 6735, 14905)
)
tibble(x = seq(5000, 30000, 10),  y= dnorm(x, 15000, 2500)) %>% ggplot(aes(x, y)) + geom_path() + theme_bw() + scale_x_continuous("Average number of students at UK University") + geom_vline(data = d, aes(xintercept = students, colour= university))
