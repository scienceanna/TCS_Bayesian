---
title: "Supplementary Materials"
author: "ADF Clarke and AE Hughes"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

```

# Intro

## Setup and Data Import

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
```

```{r}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

We will import data from all experiments. While we're at it, we will remove error trials.

```{r import-data}
source("../scripts/import_and_tidy.R")
summary(d)
```

## Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use lognormal and shifted-lognormal distributions for modelling reaction times, This allows us to avoid ever predicting impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milliseconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
- Remove the bottom and top 1% of data
  
```{r}
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4 
# remove outlier RTs

d <- our_changes_to_data(d)
```

# Use Experiments 1x and 3x to select the best model


The models discussed here have been fit in the `fit_models.R` script. In order to validate our choice of distribution, we will run our analysis using a (i) normal, (ii) lognormal, and (iii) shifted-lognormal model. Additionally, we will also consider a version of the shifted-lognormal model that is linear in $N_t$ (while all the other models are loglinear in $N_t$).

## Prior Predictions

We can take the prior model, and then use it to compute our prior predictions.

```{r glmm-prior-sample}

prior_model_nrl <- readRDS("models/prior_nrl.models")
prior_model_log <- readRDS("models/prior_log.models")
prior_model_sft <- readRDS("models/prior_sft.models")
  
```

```{r plt-prior, fig.height=10, fig.cap="Sample Prior predictions for reaction time and log(N+1) for the normal model (top), lognormal model (centre) and shifted-lognormal model (bottom). Note that these priors give the range of possible values for the RTs to fall within i.e. they constrain the model fitting process. The plots therefore show that the range of values possible is plausble, and in the case of the latter two models, does not permit impossible e.g. negative values."}
  
training_models = c("1a", "1b")

plt_nrl <- plot_model_fits_rt(training_models, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "all")
plt_log <- plot_model_fits_rt(training_models, prior_model_log, y_limits = c(0, 10), feature2plot = "all")
plt_sft <- plot_model_fits_rt(training_models, prior_model_sft, y_limits = c(0, 10), feature2plot = "all")
                           
plt_nrl / plt_log / plt_sft

# tidy up, we no longer need to keep hold of these models and plots
rm(
 prior_model_nrl, 
 prior_model_log, 
 prior_model_sft, 
 plt_nrl, plt_log, plt_sft)

```

## Fit Model and Posterior Predictions For Experiment 1

```{r glmm-compute-post-1}

m_exp1_nrl <- readRDS("models/exp_1_nrl.models")
m_exp1_log <- readRDS("models/exp_1_log.models")
m_exp1_sft <- readRDS("models/exp_1_sft.models")
#m_exp1_sft_nolog <- readRDS("models/exp_1_3_sft_nolog.models")

```

```{r plt-post, fig.height=10, fig.cap="Posterior predictions for the reaction time for the average participant and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$."}

plt_nrl <- plot_model_fits_rt(training_models, m_exp1_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(training_models, m_exp1_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(training_models, m_exp1_sft, plot_type = "fitted")
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")

plt_nrl / plt_log / plt_sft #/ plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)

```

In the above figure (Figure 2.2), we can see that all of our models give very similar relationship between $N_T$ and mean reaction time. In the next plot, we look at the model's predictions for the distribution of reaction times. 

```{r plt-post-re, fig.height=10, fig.cap="Posterior predictions for reaction time distributions and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$.", cache=TRUE}

plt_nrl <- plot_model_fits_rt(training_models, m_exp1_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(training_models, m_exp1_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(training_models, m_exp1_sft, plot_type = "predicted", y_limits = c(0, 2.5))
# plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))

plt_nrl / plt_log / plt_sft #/ plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
```



### Model Comparison

update text as we will now only use bridge sampling!

These model weights strongly suggest that the shifted-lognormal model gives a better prediction than the lognormal or normal models. It also confirmed that we do want to keep the model loglinear in $N_T$.

We will need to use the `bridge_sampler()` function later on, so let's use it here and verify that it gives the same result as `loo()`.

```{r, cache=TRUE}
bs_exp1_nrl <- bridge_sampler(m_exp1_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp1_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp1_sft, silent = TRUE)
#bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)

tibble(model = c("normal", "lognormal", "shifted-lognormal"), #, "linear in $N_T$"
       weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft)) %>% # , bs_exp1_sft_nolog 
  knitr::kable()

#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
```

From now on, we will only consider the shifted-lognormal model, as it outperforms the other models that we have considered. 

### Model diagnostics for shifted-lognormal model

The model diagnostics (Rhat values, trace plots) for our shifted-lognormal model seem okay, and are plotted below.
\tiny
```{r model_diagnostics, fig.height = 5, fig.cap = "Model diagnostics for the shifted-lognormal model."}
summary(m_exp1_sft)
plot(m_exp1_sft, pars = "^b_") 
```
\normalsize



## Fit Model and Posterior Predictions For Experiment 3

```{r glmm-compute-post-3}

m_exp3_nrl <- readRDS("models/exp_3_nrl.models")
m_exp3_log <- readRDS("models/exp_3_log.models")
m_exp3_sft <- readRDS("models/exp_3_sft.models")
#m_exp1_sft_nolog <- readRDS("models/exp_1_3_sft_nolog.models")

```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt-post3, fig.height=10, fig.cap="Posterior predictions for the reaction time for the average participant and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$."}

training_models = c("3a", "3b")

plt_nrl <- plot_model_fits_rt(training_models, m_exp3_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(training_models, m_exp3_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(training_models, m_exp3_sft, plot_type = "fitted")
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")

plt_nrl / plt_log / plt_sft #/ plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)

```

We can see that all of our models give very similar relationship between $N_T$ and mean reaction time. In the next plot, we look at the model's predictions for the distribution of reaction times. 

```{r plt-post-re3, fig.height=10, fig.cap="Posterior predictions for reaction time distributions and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$.", cache=TRUE}

plt_nrl <- plot_model_fits_rt(training_models, m_exp3_nrl, plot_type = "predicted", y_limits = c(0, 2))
plt_log <- plot_model_fits_rt(training_models, m_exp3_log, plot_type = "predicted", y_limits = c(0, 2))
plt_sft <- plot_model_fits_rt(training_models, m_exp3_sft, plot_type = "predicted", y_limits = c(0, 2))
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))

plt_nrl / plt_log / plt_sft# / plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
```


### Model Comparison

We use the `bridge_sampler()` function to compare models.

These model weights strongly suggest that the shifted-lognormal model gives a better prediction than the lognormal or normal models. It also confirmed that we do want to keep the model loglinear in $N_T$.

```{r, cache=TRUE}
bs_exp1_nrl <- bridge_sampler(m_exp3_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp3_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp3_sft, silent = TRUE)
#bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)

tibble(model = c("normal", "lognormal", "shifted-lognormal"), #, "linear in $N_T$"
       weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft)) %>% # , bs_exp1_sft_nolog 
  knitr::kable()

#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
```

From now on, we will only consider the shifted-lognormal model, as it outperforms the other models that we have considered. 

### Fit Model and Posterior Predictions For Experiment 2, and 4

Now that we have decided what the best distribution to use is, we will fit the model to the data from Experiment 2. 

```{r glmm-compute-post-24}
#load previously fitted models
m_exp2_sft <- readRDS("models/exp_2_sft.models")
m_exp4_sft <- readRDS("models/exp_4_sft.models")

```


### Use these models to compute $D$

Now we can compute $D_e$ by extracting the fixed effect slopes from the model for each experiment and condition.

```{r compute-D-1, fig.cap="Posterior estimates for $D$."}
slopes1 <- extract_fixed_slopes_from_model(m_exp1_sft)
slopes2 <- extract_fixed_slopes_from_model(m_exp2_sft)
slopes3 <- extract_fixed_slopes_from_model(m_exp3_sft)
slopes4 <- extract_fixed_slopes_from_model(m_exp4_sft)

bind_rows(
  slopes1 %>% mutate(exp = "Experiment 1"),
  slopes3 %>% mutate(exp = "Experiment 3")) %>%
  ggplot(aes(x= D, fill = d_feature)) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~exp, nrow = 2)
```

We can see that we have a posterior probability distribution for each type of distracter in both experiment 1 and 3. 


## Estimating model parameters

Now, we use the model fitted on experiment 1 (or 3) to predict the data in experiment 2 (or 4). I.e., can we predict $D_p$ for compound features based on the $D_e$ values for the related single features. 

### $D$ for compound feature distractors

Buetti et al (2019) considered three methods for calculating $D_p$: best feature, orthogonal contrast and collinear. We will use these three methods, and also a linear combination of these three.

```{r predict-D-2, fig.cap = "Estimating D, using four different calculation methods.", fig.height = 4}

Dp_samples2 <- map_dfr(c("2a", "2b", "2c"), get_Dp_samples, d, slopes1, slopes2)
Dp_samples4 <- map_dfr(c("4a", "4b", "4c"), get_Dp_samples, d, slopes3, slopes4)

Dp_samples <- bind_rows(Dp_samples2, Dp_samples4)
Dp_lines <- get_Dp_lines(Dp_samples)
plot_Dp_lines(Dp_lines)

rm(slopes1, slopes2, slopes3, slopes4)

```

### Variance!

As we are using multi-level models to describe the whole distribution of reaction times we also need to provide a $\sigma$ and a sd(Intercept). 


Random intercepts look similar:

```{r}
VarCorr(m_exp1_sft)$p_id$sd
VarCorr(m_exp2_sft)$p_id$sd
```

Residual variance looks similar, although Experiment 2 is lower than Experiment 1. 

```{r}
VarCorr(m_exp1_sft)$residual$sd
VarCorr(m_exp2_sft)$residual$sd
```

It seems possible to model Experiment 2 using the variances from Experiment 1.


## Predicting Reaction Times

In order to predict reaction times, we will specify a new version of our model.

We can feed the predicted values for $D$ into our `brms` model as a prior, and then use that to simulate new trials.

```{r gen-predictions, fig.width = 10, fig.height = 10, cache=TRUE, message=FALSE}

# first, summarise our Dp samples to give mu and sigma.

compute_rt_predictions <- function(test_data = c("2a", "2b", "2c"), meth, onefm, twofm) {
  Dp_samples %>%
    filter(method == meth, exp_id %in% test_data) %>%
    group_by(exp_id, d_feature) %>%
    summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
    mutate(
      d_feature = as_factor(d_feature),
      method = meth) -> Dp_summary

  # now define and run new model! 
  
  model_params <- set_up_predict_model(test_data, "shifted_lognormal", meth, Dp_summary, onefm, twofm)
  
  m_prt <- run_model(model_params, ppc = "only")
    
  return(m_prt)
  
}
test_set <- c("2a", "2b", "2c")
m_prt_best_feature2 <- compute_rt_predictions(test_set,  meth = "best_feature", m_exp1_sft, m_exp2_sft)
m_prt_collinear2 <- compute_rt_predictions(test_set, meth = "collinear", m_exp1_sft, m_exp2_sft)
m_prt_orthog_contrast2 <- compute_rt_predictions(test_set, meth = "orthog_contrast", m_exp1_sft, m_exp2_sft)

bs_bfeat <- bridge_sampler(m_prt_best_feature2, silent = TRUE)
bs_orth <- bridge_sampler(m_prt_orthog_contrast2, silent = TRUE)
bs_col <- bridge_sampler(m_prt_collinear2, silent = TRUE)


post_prob(bs_bfeat, bs_col, bs_orth)



test_set <- c("4a", "4b", "4c")
m_prt_best_feature4 <- compute_rt_predictions(test_set, meth = "best_feature", m_exp3_sft, m_exp4_sft)
m_prt_collinear4 <- compute_rt_predictions(test_set, meth = "collinear", m_exp3_sft, m_exp4_sft)
m_prt_orthog_contrast4 <- compute_rt_predictions(test_set, meth = "orthog_contrast", m_exp3_sft, m_exp4_sft)

bs_bfeat <- bridge_sampler(m_prt_best_feature4, silent = TRUE)
bs_orth <- bridge_sampler(m_prt_orthog_contrast4, silent = TRUE)
bs_col <- bridge_sampler(m_prt_collinear4, silent = TRUE)


post_prob(bs_bfeat,bs_col, bs_orth) 


rm(bs_bfeat,bs_col, bs_orth, bs_lint)

```


Note, this plot is for how we expect the average person to perform in experiment 2, using the orthogonal contrast combination method: 

```{r plot-exp2-predictions, fig.height = 6, fig.cap="Reaction time predictions for the average person for the orthogonal contrast method, predicting reaction times in Experiment 2."}


plot_model_fits_rt(c("2a", "2b", "2c"), m_prt_orthog_contrast2, y_limits = c(0.4, 0.8), n_row = 3, plot_type = "fitted")
plot_model_fits_rt(c("4a", "4b", "4c"), m_prt_orthog_contrast4, y_limits = c(0.4, 0.8), n_row = 3, plot_type = "fitted")
```

```{r, fig.height = 6}

plot_model_fits_rt(c("2a", "2b", "2c"), m_prt_orthog_contrast2, y_limits = c(0, 1.6), n_row = 3, plot_type = "predicted")
plot_model_fits_rt(c("4a", "4b", "4c"), m_prt_orthog_contrast4, y_limits = c(0, 1.6), n_row = 3, plot_type = "predicted")


```


