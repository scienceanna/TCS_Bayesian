---
title: "Supplementary Materials"
author: "ADF Clarke and AE Hughes"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

```

# Intro

## Setup and Data Import

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
```

```{r}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

We will import data from all experiments. While we're at it, we will remove error trials.

```{r import-data}
source("../scripts/import_and_tidy.R")
summary(d)
```

## Switching to a Bayesian Multi-Level Framework

Now that we have verified that we can re-create the original results, we switch to a Bayesian multi-level framework. We make the following important changes:

  - Modelling trial data, rather than pooled mean reaction time data. This allows us to fit a model that can generate data at the trial level, and account 
  - Use lognormal and shifted-lognormal distributions for modelling reaction times, This allows us to avoid ever predicting impossible negative reaction times. It also helps us to account for the skew in the distribution
  - We will switch from using milliseconds to seconds. This leaves us with most values around 0.5-1seconds, which will help model fitting. I.e., a more standardised scale. 
  - Recode Experiment 1a and 1b to Experiment 1, Experiment 2a, 2b and 2c to Experiment 2, etc.
- Remove the bottom and top 1% of data
  
```{r}
# switch from ms to seconds
# recode experiment as 1, 2, 3 and 4 
# remove outlier RTs

d <- our_changes_to_data(d)
```

# Use Experiments 1x and 3x to select the best model


The models discussed here have been fit in the `fit_models.R` script. In order to validate our choice of distribution, we will run our analysis using a (i) normal, (ii) lognormal, and (iii) shifted-lognormal model. Additionally, we will also consider a version of the shifted-lognormal model that is linear in $N_t$ (while all the other models are loglinear in $N_t$).

## Prior Predictions

We can take the prior model, and then use it to compute our prior predictions.

```{r glmm-prior-sample}

prior_model_nrl <- readRDS("models/prior_nrl.models")
prior_model_log <- readRDS("models/prior_log.models")
prior_model_sft <- readRDS("models/prior_sft.models")
  
```

```{r plt-prior, fig.height=10, fig.cap="Sample Prior predictions for reaction time and log(N+1) for the normal model (left), lognormal model (centre) and shifted-lognormal model (right)."}
  
training_models = c("1a", "1b")

plt_nrl <- plot_model_fits_rt(training_models, prior_model_nrl, y_limits = c(-2, 10),feature2plot = "all")
plt_log <- plot_model_fits_rt(training_models, prior_model_log, y_limits = c(0, 10), feature2plot = "all")
plt_sft <- plot_model_fits_rt(training_models, prior_model_sft, y_limits = c(0, 10), feature2plot = "all")
                           
plt_nrl / plt_log / plt_sft

# tidy up, we no longer need to keep hold of these models and plots
rm(
 prior_model_nrl, 
 prior_model_log, 
 prior_model_sft, 
 plt_nrl, plt_log, plt_sft)

```

## Fit Model and Posterior Predictions For Experiment 1

```{r glmm-compute-post-1}

m_exp1_nrl <- readRDS("models/exp_1_nrl.models")
m_exp1_log <- readRDS("models/exp_1_log.models")
m_exp1_sft <- readRDS("models/exp_1_sft.models")
#m_exp1_sft_nolog <- readRDS("models/exp_1_3_sft_nolog.models")

```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt-post, fig.height=10, fig.cap="Posterior predictions for the reaction time for the average participant and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$."}

plt_nrl <- plot_model_fits_rt(training_models, m_exp1_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(training_models, m_exp1_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(training_models, m_exp1_sft, plot_type = "fitted")
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")

plt_nrl / plt_log / plt_sft #/ plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)

```

We can see that all of our models give very similar relationship between $N_T$ and mean reaction time. In the next plot, we look at the model's predictions for the distribution of reaction times. 

```{r plt-post-re, fig.height=10, fig.cap="Posterior predictions for reaction time distributions and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$.", cache=TRUE}

plt_nrl <- plot_model_fits_rt(training_models, m_exp1_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(training_models, m_exp1_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(training_models, m_exp1_sft, plot_type = "predicted", y_limits = c(0, 2.5))
# plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))

plt_nrl / plt_log / plt_sft #/ plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
```



### Model Comparison

update text as we will now only use bridge sampling!

These model weights strongly suggest that the shifted-lognormal model gives a better prediction than the lognormal or normal models. It also confirmed that we do want to keep the model loglinear in $N_T$.

We will need to use the `bridge_sampler()` function later on, so let's use it here and verify that it gives the same result as `loo()`.

```{r, cache=TRUE}
bs_exp1_nrl <- bridge_sampler(m_exp1_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp1_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp1_sft, silent = TRUE)
#bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)

tibble(model = c("normal", "lognormal", "shifted-lognormal"), #, "linear in $N_T$"
       weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft)) %>% # , bs_exp1_sft_nolog 
  knitr::kable()

#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
```

From now on, we will only consider the shifted-lognormal model, as it outperforms the other models that we have considered. 

### Model diagnostics for shifted-lognormal model

The model diagnostics (Rhat values, trace plots) for our shifted-lognormal model seem okay, and are plotted below.
\tiny
```{r model_diagnostics, fig.height = 5, fig.cap = "Model diagnostics for the shifted-lognormal model."}
summary(m_exp1_sft)
plot(m_exp1_sft, pars = "^b_") 
```
\normalsize



## Fit Model and Posterior Predictions For Experiment 3

```{r glmm-compute-post-3}

m_exp3_nrl <- readRDS("models/exp_3_nrl.models")
m_exp3_log <- readRDS("models/exp_3_log.models")
m_exp3_sft <- readRDS("models/exp_3_sft.models")
#m_exp1_sft_nolog <- readRDS("models/exp_1_3_sft_nolog.models")

```

The plots before show our estimates for average participant to lie. The regions illustrate the distribution of reaction times estimated by our model. 

```{r plt-post3, fig.height=10, fig.cap="Posterior predictions for the reaction time for the average participant and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$."}

training_models = c("3a", "3b")

plt_nrl <- plot_model_fits_rt(training_models, m_exp3_nrl, plot_type = "fitted")
plt_log <- plot_model_fits_rt(training_models, m_exp3_log, plot_type = "fitted")
plt_sft <- plot_model_fits_rt(training_models, m_exp3_sft, plot_type = "fitted")
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "fitted")

plt_nrl / plt_log / plt_sft #/ plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)

```

We can see that all of our models give very similar relationship between $N_T$ and mean reaction time. In the next plot, we look at the model's predictions for the distribution of reaction times. 

```{r plt-post-re3, fig.height=10, fig.cap="Posterior predictions for reaction time distributions and log(N+1) for (from top to bottom) (i) the normal model, (ii) the lognormal model, (iii) the shifted-lognormal model, and (iv) the shifted lognormal model with linear $N_T$.", cache=TRUE}

plt_nrl <- plot_model_fits_rt(training_models, m_exp3_nrl, plot_type = "predicted", y_limits = c(0, 2.5))
plt_log <- plot_model_fits_rt(training_models, m_exp3_log, plot_type = "predicted", y_limits = c(0, 2.5))
plt_sft <- plot_model_fits_rt(training_models, m_exp3_sft, plot_type = "predicted", y_limits = c(0, 2.5))
#plt_sft_nolog <- plot_model_fits_rt(1, m_exp1_sft_nolog, plot_type = "predicted", y_limits = c(0, 2.5))

plt_nrl / plt_log / plt_sft# / plt_sft_nolog

rm(plt_nrl, plt_log, plt_sft, plt_sft_nolog)
```


### Model Comparison

update text as we will now only use bridge sampling!

These model weights strongly suggest that the shifted-lognormal model gives a better prediction than the lognormal or normal models. It also confirmed that we do want to keep the model loglinear in $N_T$.

We will need to use the `bridge_sampler()` function later on, so let's use it here and verify that it gives the same result as `loo()`.

```{r, cache=TRUE}
bs_exp1_nrl <- bridge_sampler(m_exp3_nrl, silent = TRUE)
bs_exp1_log <- bridge_sampler(m_exp3_log, silent = TRUE)
bs_exp1_sft <- bridge_sampler(m_exp3_sft, silent = TRUE)
#bs_exp1_sft_nolog <- bridge_sampler(m_exp1_sft_nolog, silent = TRUE)

tibble(model = c("normal", "lognormal", "shifted-lognormal"), #, "linear in $N_T$"
       weight = post_prob(bs_exp1_nrl, bs_exp1_log, bs_exp1_sft)) %>% # , bs_exp1_sft_nolog 
  knitr::kable()

#remove the models that we no longer need
rm(m_exp1_nrl, m_exp1_log, m_exp1_sft_nolog)
```

From now on, we will only consider the shifted-lognormal model, as it outperforms the other models that we have considered. 







### Fit Model and Posterior Predictions For Experiment 2, and 4

Now that we have decided what the best distribution to use is, we will fit the model to the data from Experiment 2. 

```{r glmm-compute-post-24}
#load previously fitted models
<<<<<<< Updated upstream
#m_exp2_sft <- readRDS("models/exp_2_sft.models")
#m_exp4_sft <- readRDS("models/exp_4_sft.models")
=======
m_exp2_sft <- readRDS("models/exp_2_sft.models")
m_exp4_sft <- readRDS("models/exp_4_sft.models")
>>>>>>> Stashed changes
```


### Use these models to compute $D$

Now we can compute $D_e$ by extracting the fixed effect slopes from the model for each experiment and condition.

```{r compute-D-1, fig.cap="Posterior estimates for $D$."}
slopes1 <- extract_fixed_slopes_from_model(m_exp1_sft)
slopes2 <- extract_fixed_slopes_from_model(m_exp2_sft)
slopes3 <- extract_fixed_slopes_from_model(m_exp3_sft)
slopes4 <- extract_fixed_slopes_from_model(m_exp4_sft)

bind_rows(
  slopes1 %>% mutate(exp = "Experiment 1"),
  slopes3 %>% mutate(exp = "Experiment 3")) %>%
  ggplot(aes(x= D, fill = d_feature)) + 
  geom_density(alpha = 0.5) +
  facet_wrap(~exp, nrow = 2)
```

We can see that we have a posterior probability distribution for each type of distracter in both experiment 1 and 3. 


## Estimating model parameters

Now, we use the model fitted on experiment 1 (or 3) to predict the data in experiment 2 (or 4). I.e., can we predict $D_p$ for compound features based on the $D_e$ values for the related single features. 

### $D$ for compound feature distractors

Buetti et al (2019) considered three methods for calculating $D_p$: best feature, orthogonal contrast and collinear. We will use these three methods, and also a linear combination of these three.

```{r predict-D-2, fig.cap = "Estimating D, using four different calculation methods.", fig.height = 4}

Dp_samples <- bind_rows(
   map_dfr(c("2a", "2b", "2c"), get_Dp_samples, d, slopes1, slopes2),
    map_dfr(c("4a", "4b", "4c"), get_Dp_samples, d, slopes1, slopes2))

# get best possible linear fit of the various methods!
Dp_samples %>% 
  pivot_wider(
    c(exp_id, d_feature, iter, De), 
    names_from = method, values_from = Dp) -> d_lmer

# find mle best fit
m_lmer <- lme4::lmer(data = d_lmer, De ~ best_feature + orthog_contrast + collinear + (1|iter))

d_lmer %>% 
  mutate(linear_comb = predict(m_lmer)) %>%
  pivot_longer(
    c(best_feature, orthog_contrast, collinear, linear_comb), 
    names_to = "method", 
    values_to = "Dp") %>%
  mutate(method = fct_relevel(method, "linear_comb", after = Inf)) -> Dp_samples

rm(d_lmer, m_lmer)

Dp_lines <- get_Dp_lines(Dp_samples)
plot_Dp_lines(Dp_lines)

rm(slopes1, slopes2, slopes3, slopes4)

```

