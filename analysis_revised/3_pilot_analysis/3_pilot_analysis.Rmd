---
title: "Supplementary Materials: Pilot Analysis"
author: "ADF Clarke and AE Hughes"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

```

# Intro

## Setup and Data Import

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
```

```{r}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

## Import and Remove Outliers 

We will import data from pilot experiment. 

```{r import-data}
source("1_pre_process_pilot.R")

summary(d1)
summary(d2)
```

# Fit Models to Data

```{r}

# source("2_fit_pilot_models.R")

```

todo : plot prior predictions

## Hypothesis 1 

Verify that using a shift-lognormal gives a better mdoel than a lognormal or normal.

```{r, cache=TRUE}
m_sft <- readRDS("pilot1.model")
m_nrl <- readRDS("pilot1_normal.model")
m_log <- readRDS("pilot1_lognormal.model")

tibble(model = c("shifted lognormal", "normal", "lognormal"),
  LOO = model_weights(m_sft, m_nrl, m_log, weights = "loo"),
             WAIC = model_weights(m_sft, m_nrl, m_log, weights = "waic")) %>%
  knitr::kable()

rm(m_nrl, m_log)
```

## Hypothesis 2

Verify that using log(number of distracters) is superior to n(distracters).

```{r, cache=TRUE}
m_lin <- readRDS("pilot1_linear.model")

tibble(model = c("loglinear in n", "linear in n"),
             LOO = model_weights(m_sft, m_lin, weights = "loo"),
             WAIC = model_weights(m_sft, m_lin, weights = "waic")) %>%
  knitr::kable()

rm(m_lin)
```

# Hypothesis 3

