---
title: "Supplementary Materials: Pilot Analysis"
author: "ADF Clarke and AE Hughes"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

```

# Intro

## Setup and Data Import

```{r load-packages, include = FALSE}
library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)
library(latex2exp)
```

```{r}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

## Import and Remove Outliers 

We will import data from pilot experiment. 

```{r import-data}
source("1_pre_process_pilot.R")

summary(d1)
summary(d2)
```

# Fit Models to Data

```{r}

# source("2_fit_pilot_models.R")

```

todo : plot prior predictions

## Hypothesis 1 

Verify that using a shift-lognormal gives a better mdoel than a lognormal or normal.

```{r, cache=TRUE}
m_sft <- readRDS("pilot1.model")
m_nrl <- readRDS("pilot1_normal.model")
m_log <- readRDS("pilot1_lognormal.model")

tibble(model = c("shifted lognormal", "normal", "lognormal"),
  LOO = model_weights(m_sft, m_nrl, m_log, weights = "loo"),
             WAIC = model_weights(m_sft, m_nrl, m_log, weights = "waic")) %>%
  knitr::kable()

rm(m_nrl, m_log)
```

## Hypothesis 2

Verify that using log(number of distracters) is superior to n(distracters).

```{r, cache=TRUE}
m_lin <- readRDS("pilot1_linear.model")

tibble(model = c("loglinear in n", "linear in n"),
             LOO = model_weights(m_sft, m_lin, weights = "loo"),
             WAIC = model_weights(m_sft, m_lin, weights = "waic")) %>%
  knitr::kable()

rm(m_lin, m_sft)
```

# Hypothesis 3

## Fixed effect of D (group average)

```{r}
source("get_slopes_fun.R")


m1 <- readRDS("pilot1.model")
samples1 <- get_slopes(m1, 1) %>% select(-observer, -rD) %>% distinct()


samples1 %>% mutate(feature_type = if_else(
  feature %in% c("purple", "orange", "pink"), "colour", "shape")) %>%
  ggplot(aes(D, fill = feature)) + 
  geom_density(alpha = 0.33) + 
  facet_wrap(~feature_type)


m2 <- readRDS("pilot2_random.model") 
samples2 <- get_slopes(m2, 1) %>% select(-observer, -rD) %>% distinct()

samples2 %>% separate(feature, into = c("colour", "shape")) %>%
  ggplot(aes(D, fill = colour)) + 
  geom_density(alpha = 0.33) + 
  facet_grid(.~shape)

```

```{r}

calc_D <- function(feature1, feature2) {
  
  D1 <- filter(samples1, feature == feature1)$D
  D2 <- filter(samples1, feature == feature2)$D
  
  # now calculate D_overall using the three proposed methods
  D_collinear = 1/((1/D1) + (1/D2))
  D_best_feature = pmin(D1, D2)
  D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))
  
  return(tibble(.draw = 1:2000,
                feature1 = feature1, feature2 = feature2,
                D_collinear = D_collinear,
                D_best_feature = D_best_feature,
                D_orth_contrast = D_orth_contrast))
  
}


things_to_calc <- samples2 %>% select( -D, -.draw) %>%
  distinct() %>%
  separate(feature, c("feature1", "feature2"))


slopes <- pmap_df(things_to_calc, calc_D) %>% full_join(samples2) %>%
  pivot_longer(c(D_collinear, D_best_feature, D_orth_contrast), names_to = "method", values_to = "Dp") %>%
  group_by(feature1, feature2, method) %>%
  summarise(mu = mean(Dp),
            sd = sd(Dp)) %>%
  mutate(method = str_remove(method, "D_"),
         slope = paste0("feature", feature1, "_", feature2, ":lnd"))



```