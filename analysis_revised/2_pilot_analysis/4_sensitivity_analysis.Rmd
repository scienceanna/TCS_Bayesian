---
title: "Supplementary materials: sensitivity analysis"
author: "ADF Clarke and AE Hughes"
output: bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
   fig.height = 3,
  fig.align = "center")

```

# Intro

## Set up

```{r load-packages, include = FALSE}

library(tidyverse)
library(tidybayes)
library(brms)
library(patchwork)
library(latex2exp)
library(ggpmisc)
library(bridgesampling)

```

```{r, message = FALSE, warning = FALSE}
# set ggplot2 theme
theme_set(see::theme_abyss())

# use parallel cores for mcmc chains!
options(mc.cores = parallel::detectCores())

n_chains = 4
n_itr = 1000

# reduce the number of decimal places
options(digits = 3)

# functions used for our Bayesian re-analysis
source("../scripts/our_functions.R")
source("1_pre_process_pilot.R")

# set seed to make sure everything is reproducible 
set.seed(100320021)
```

## Merging d1 and d2

```{r}

d2 %>% unite(feature, feature1, feature2) %>%
  bind_rows(d1) -> d

```

## Fitting model

```{r, eval = FALSE}

my_f <- bf(rt ~ feature:lnd + (feature:lnd|observer), 
           ndt ~ 1 + (1|observer))

my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))

my_prior <- c(
  prior_string("normal(-0.5, 0.3)", class = "Intercept"),
  prior_string("normal(0, 0.2)", class = "b"),
  prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
  prior_string("cauchy(0, 0.4)", class = "sigma"),
  prior_string("cauchy(0, 0.05)", class = "sd"),
  prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))

n_chains = 4
n_itr = 1000

# now run model
m <- brm(
  my_f, 
  data = d,
  family = brmsfamily("shifted_lognormal"),
  prior = my_prior,
  chains = n_chains,
  iter = n_itr,
  init = my_inits,
  ##stanvars = my_stanvar,
  save_pars = save_pars(all=TRUE),
  silent = TRUE
)

saveRDS(m, "sim_sense.model")

```

## Read in model and simulate new data

```{r}

m <- readRDS("sim_sense.model")

n_obs <-  5
n_trials <- 15

d %>% modelr::data_grid(feature, lnd, observer = 1:n_obs) %>%
  add_predicted_draws(m, allow_new_levels = TRUE, ndraws = n_trials) %>%
  ungroup %>%
  select(observer, feature, lnd, rt = ".prediction") -> dsim

# remove 1st and 100th percentile RT
dsim %>% filter(
  rt > quantile(rt, 0.01), 
  rt < quantile(rt, 0.99)) -> dsim

d1 <- filter(dsim, !str_detect(feature, "_"))
d2 <- filter(dsim, str_detect(feature, "_")) %>% separate(feature, c("feature1", "feature2"))  

ggplot(d1, aes(lnd, rt)) + geom_jitter(colour = "white", alpha = 0.1) + facet_wrap(~feature)

```

# Fit training model

```{r, cache = TRUE, warning = FALSE, message = FALSE}

my_f <- brms::bf(rt ~ feature:lnd + (feature:lnd|observer), 
           ndt ~ 1 + (1|observer))

my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))

my_prior <- c(
  prior_string("normal(-0.5, 0.3)", class = "Intercept"),
  prior_string("normal(0, 0.2)", class = "b"),
  prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
  prior_string("cauchy(0, 0.4)", class = "sigma"),
  prior_string("cauchy(0, 0.05)", class = "sd"),
  prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))


# now run model
m <- brm(
  my_f, 
  data = d1,
  family = brmsfamily("shifted_lognormal"),
  prior = my_prior,
  chains = n_chains,
  iter = n_itr,
  inits = my_inits,
  ##stanvars = my_stanvar,
  save_pars = save_pars(all=TRUE),
  silent = TRUE
)

saveRDS(m, "pilot1_sensitivity.model")


```

## Fit test models

```{r, cache = TRUE, warning = FALSE, message = FALSE}

d2 <- d2 %>% unite(feature, feature1, feature2)


my_f <- brms::bf(rt ~ feature:lnd + (feature:lnd|observer), 
           ndt ~ 1 + (1|observer))

my_inits <- list(list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10), list(Intercept_ndt = -10))

my_prior <- c(
  prior_string("normal(-0.5, 0.3)", class = "Intercept"),
  prior_string("normal(0, 0.2)", class = "b"),
  prior_string("normal(-1, 0.5)", class = "Intercept", dpar = "ndt" ),
  prior_string("cauchy(0, 0.4)", class = "sigma"),
  prior_string("cauchy(0, 0.05)", class = "sd"),
  prior_string("cauchy(0, 0.05)", class = "sd", dpar = "ndt"))

# now run model
m <- brm(
  my_f, 
  data = d2,
  family = brmsfamily("shifted_lognormal"),
  prior = my_prior,
  chains = n_chains,
  iter = n_itr,
  inits = my_inits,
  ##stanvars = my_stanvar,
  save_pars = save_pars(all=TRUE),
  silent = TRUE
)


saveRDS(m, "pilot2_sensitivity_random.model")

```

# Hypothesis 3

## Fixed effect of D (group average)

```{r message=FALSE, warning=FALSE}
source("get_slopes_fun.R")

m1 <- readRDS("pilot1_sensitivity.model")

samples1 <- get_slopes(m1, 1) %>% select(-observer, -rD) %>% distinct() %>%
   filter(!str_detect(feature, '_')) 

# circle, diamond, orange, pink, purple, triangle
colourPalette <- c("#aadce0", "#72bcd5", "#e78429", "#ed968c", "#7c4b73", "528fad")

samples1 %>% mutate(feature_type = if_else(
  feature %in% c("purple", "orange", "pink"), "colour", "shape")) %>%
  ggplot(aes(D, fill = feature)) + 
  geom_density(alpha = 0.33) + 
  facet_wrap(~feature_type) +
  scale_fill_manual(values=colourPalette)

```

```{r, message = FALSE, warning = FALSE}

m2 <- readRDS("pilot2_sensitivity_random.model") 
samples2 <- get_slopes(m2, 1) %>% select(-observer, -rD) %>% distinct()


calc_D <- function(feature1, feature2) {
  
  D1 <- filter(samples1, feature == feature1)$D
  D2 <- filter(samples1, feature == feature2)$D
  
  # now calculate D_overall using the three proposed methods
  D_collinear = 1/((1/D1) + (1/D2))
  D_best_feature = pmin(D1, D2)
  D_orth_contrast =  1/sqrt(1/(D1^2) + (1/D2^2))
  
 return(tibble(.draw = 1:2000,
               feature = paste(feature1, feature2, sep = "_"),
                feature1 = feature1, feature2 = feature2,
                collinear = D_collinear,
                `best feature` = D_best_feature,
                `orthogonal contrast` = D_orth_contrast))
  
}


things_to_calc <- samples2 %>% select( -D, -.draw) %>%
  distinct() %>%
  separate(feature, c("feature1", "feature2"))


slopes <- pmap_df(things_to_calc, calc_D) %>% full_join(samples2, by = c(".draw", "feature")) %>%
  pivot_longer(c(collinear, `best feature`, `orthogonal contrast`), names_to = "method", values_to = "Dp") %>%
  select(-feature) %>%
  pivot_longer(c(D, Dp), names_to = "type", values_to = "D") %>%
  group_by(feature1, feature2, method, type)

slopes %>%
  median_hdci(D) %>%
  unite(D, D, .lower, .upper) %>%
  select(-.width, -.point, -.interval) %>%
  pivot_wider(names_from = "type", values_from = "D") %>%
  separate(D, into = c("De", "De_min", "De_max"), sep = "_", convert = TRUE) %>%
  separate(Dp, into = c("Dp", "Dp_min", "Dp_max"), sep = "_", convert=  TRUE) %>%
  ggplot(aes(x = Dp, xmin = Dp_min, xmax = Dp_max, y = De, ymin = De_min, ymax = De_max)) + 
  geom_point() + 
  geom_errorbar(alpha = 0.5, colour = "yellow") + 
  geom_errorbarh(alpha = 0.5, colour = "yellow") + 
  geom_abline(linetype = 2) + 
  geom_smooth(method = "lm", fullrange  = T, colour = "violetred3") + 
      stat_poly_eq(formula = y ~ x, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "*plain(\",\")~")), 
               parse = TRUE, size = 2.8, label.y = 0.9, coef.digits = 3, rr.digits = 4, colour="yellow1") +
  facet_wrap(~method, scales = "free") +
  scale_colour_manual(values = c("yellow1", "yellow1", "yellow1"))
```

# Hypothesis 4: Predicting Reaction Times

```{r, message = FALSE, warning = FALSE, echo = FALSE}
compute_rt_predictions <- function(slopes, meth) {
 
   slopes %>%
    pivot_wider(names_from = type, values_from = D) %>%
    filter(method == meth) %>%
    group_by(feature1, feature2) %>%
    summarise(mu = mean(Dp), sigma = sd(Dp), .groups = "drop") %>%
    mutate(
      d_feature = as_factor(paste(feature1, feature2)),
      method = meth) -> Dp_summary

  # now define and run new model! 
  
my_f <- brms::bf(rt ~ feature:lnd + (feature:lnd|observer), 
           ndt ~ 1 + (1|observer))
    
    my_inits <- list(list(Intercept_ndt = -10)    )
    
    
  intercept_mu <- fixef(m)["Intercept", 1]
  intercept_sd <- fixef(m)["Intercept", 2]
  
  ndt_int_mu <- fixef(m)["ndt_Intercept", 1]
  ndt_int_sd <- fixef(m)["ndt_Intercept", 2]
  

  sigma_mean <-  VarCorr(m)$residual$sd[1]
  sigma_sd   <-  VarCorr(m)$residual$sd[2]
  
  sd_mean <- VarCorr(m)$observer$sd[1,1]
  sd_sd <- VarCorr(m)$observer$sd[1,2]
  
  sd_ndt_mean <- VarCorr(m)$observer$sd[2,1]
  sd_ndt_sd <- VarCorr(m)$observer$sd[2,2]
  
  slopes <-paste0("feature", Dp_summary$feature1, "_", Dp_summary$feature2, ":lnd")
  slopes_mu <-Dp_summary$mu 
  slopes_sd <-Dp_summary$sigma 
  
   my_prior <-  c(
    prior_string(paste("normal(", intercept_mu, ",",  intercept_sd, ")", sep = ""), class = "Intercept"),
    prior_string(paste("normal(", slopes_mu, ",",  slopes_sd, ")", sep = ""), class = "b", coef = slopes),
    prior_string(paste("normal(", sigma_mean, ",", sigma_sd, ")", sep = ""), class = "sigma"),
    prior_string(paste("normal(", sd_mean, ",", sd_sd, ")", sep = ""), class = "sd"),
    prior_string(paste("normal(",ndt_int_mu, ", ", ndt_int_sd, ")"), class = "Intercept", dpar = "ndt" ),
    prior_string(paste("normal(",sd_ndt_mean,",", sd_ndt_sd,")"), class = "sd", dpar = "ndt"))
    
    stanvars <- stanvar(sigma_mean, name='sigma_mean') + 
    stanvar(sigma_sd, name='sigma_sd') + 
    stanvar(sd_mean, name='sd_mean') + 
    stanvar(sd_sd, name='sd_sd')
   
  m_prt <- brm(
    my_f, 
    data = d2,
    family = brmsfamily("shifted_lognormal"),
    prior = my_prior,
    chains = 1,
    iter = 5000,
    inits = my_inits,
    stanvars = stanvars,
    save_pars = save_pars(all=TRUE),
    silent = TRUE,
    sample_prior = "only",
    refresh = 0
  )

  return(m_prt)
}


```

```{r, cache=TRUE, message = FALSE, warning = FALSE, echo = FALSE}
  #d2 <- d2 %>% unite(feature, feature1, feature2)
m_col <- compute_rt_predictions(slopes, "collinear")

d2 %>% modelr::data_grid(feature, lnd) %>%
  add_predicted_draws(m_col, re_formula = NA) %>%
  mean_hdci(.width = c(0.53, 0.97)) %>%
  ggplot(aes(lnd)) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper, group = .width), alpha = 0.3, fill = "pink") + 
  geom_jitter(data = d2, aes(y = rt), colour = "white", alpha = 0.1) + 
  facet_wrap(~feature, nrow = 2)

m_bfe <- compute_rt_predictions(slopes, "best feature")
m_orc <- compute_rt_predictions(slopes, "orthogonal contrast")
```


```{r, echo = FALSE, message = FALSE, warning = FALSE}
m_col <- bridge_sampler(m_col, silent = TRUE)
m_bfe <- bridge_sampler(m_bfe, silent = TRUE)
m_orc <- bridge_sampler(m_orc, silent = TRUE)
```


```{r}
post_prob(m_col, m_bfe, m_orc) %>%
  knitr::kable()

```